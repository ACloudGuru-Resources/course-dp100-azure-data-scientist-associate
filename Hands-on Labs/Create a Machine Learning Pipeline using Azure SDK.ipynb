{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Create a Machine Learning Pipeline using Azure SDK\n",
        "\n",
        "In this hands-on lab scenario you are a Data Scientist for Awesome Company. Recently the company has been using Azure Machine Learning Service to implement and run their machine learning workloads. As part of this effort, you are learning to create pipelines programmatically using the Azure SDK. You'll be utilizing an open dataset on diabetes in order to help Awesome Company build a pipeline for diabetes research.\n",
        "\n",
        "To accomplish your goal, the following should be completed:\n",
        "* Create a workspace\n",
        "* Create compute resources\n",
        "* Create and run a pipeline"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to your workspace\n",
        "\n",
        "To get started, connect to your workspace."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import azureml.core\n",
        "from azureml.core import Workspace\n",
        "\n",
        "# Load the workspace from the saved config file\n",
        "ws = Workspace.from_config()\n",
        "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ready to use Azure ML 1.27.0 to work with lkftest\n"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1621349701284
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prepare data\n",
        "\n",
        "Awesome Company is using an open dataset on diabetes patients as part of their research. The cell below will create the required dataset."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Dataset\n",
        "\n",
        "default_ds = ws.get_default_datastore()\n",
        "\n",
        "if 'diabetes dataset' not in ws.datasets:\n",
        "    default_ds.upload_files(files=['./data/diabetes.csv', './data/diabetes2.csv'], # Upload the diabetes csv files in /data\n",
        "                        target_path='diabetes-data/', # Put it in a folder path in the datastore\n",
        "                        overwrite=True, # Replace existing files of the same name\n",
        "                        show_progress=True)\n",
        "\n",
        "    #Create a tabular dataset from the path on the datastore (this may take a short while)\n",
        "    tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'diabetes-data/*.csv'))\n",
        "\n",
        "    # Register the tabular dataset\n",
        "    try:\n",
        "        tab_data_set = tab_data_set.register(workspace=ws, \n",
        "                                name='diabetes dataset',\n",
        "                                description='diabetes data',\n",
        "                                tags = {'format':'CSV'},\n",
        "                                create_new_version=True)\n",
        "        print('Dataset registered.')\n",
        "    except Exception as ex:\n",
        "        print(ex)\n",
        "else:\n",
        "    print('Dataset already registered.')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset already registered.\n"
          ]
        }
      ],
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1621349751934
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a folder for our python scripts"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "experiment_folder = 'diabetes_pipeline'\n",
        "os.makedirs(experiment_folder, exist_ok=True)\n",
        "\n",
        "print(experiment_folder)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diabetes_pipeline\n"
          ]
        }
      ],
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1621349757612
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a data preparation script"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/prep_diabetes.py\n",
        "# Import libraries\n",
        "import os\n",
        "import argparse\n",
        "import pandas as pd\n",
        "from azureml.core import Run\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Get parameters\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--input-data\", type=str, dest='raw_dataset_id', help='raw dataset')\n",
        "parser.add_argument('--prepped-data', type=str, dest='prepped_data', default='prepped_data', help='Folder for results')\n",
        "args = parser.parse_args()\n",
        "save_folder = args.prepped_data\n",
        "\n",
        "# Get the experiment run context\n",
        "run = Run.get_context()\n",
        "\n",
        "# Load the data\n",
        "print(\"Loading Data...\")\n",
        "diabetes = run.input_datasets['raw_data'].to_pandas_dataframe()\n",
        "\n",
        "# Log raw row count\n",
        "row_count = (len(diabetes))\n",
        "run.log('raw_rows', row_count)\n",
        "\n",
        "# Remove nulls\n",
        "diabetes = diabetes.dropna()\n",
        "\n",
        "# Normalize the numeric columns\n",
        "scaler = MinMaxScaler()\n",
        "num_cols = ['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree']\n",
        "diabetes[num_cols] = scaler.fit_transform(diabetes[num_cols])\n",
        "\n",
        "# Log processed rows\n",
        "row_count = (len(diabetes))\n",
        "run.log('processed_rows', row_count)\n",
        "\n",
        "# Save the prepped data\n",
        "print(\"Saving Data...\")\n",
        "os.makedirs(save_folder, exist_ok=True)\n",
        "save_path = os.path.join(save_folder,'data.csv')\n",
        "diabetes.to_csv(save_path, index=False, header=True)\n",
        "\n",
        "# End the run\n",
        "run.complete()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing diabetes_pipeline/prep_diabetes.py\n"
          ]
        }
      ],
      "execution_count": 10,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a script to train the model"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $experiment_folder/train_diabetes.py\n",
        "# Import libraries\n",
        "from azureml.core import Run, Model\n",
        "import argparse\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get parameters\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument(\"--training-folder\", type=str, dest='training_folder', help='training data folder')\n",
        "args = parser.parse_args()\n",
        "training_folder = args.training_folder\n",
        "\n",
        "# Get the experiment run context\n",
        "run = Run.get_context()\n",
        "\n",
        "# Load the prepared data file\n",
        "print(\"Loading Data...\")\n",
        "file_path = os.path.join(training_folder,'data.csv')\n",
        "diabetes = pd.read_csv(file_path)\n",
        "\n",
        "# Separate features and labels\n",
        "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
        "\n",
        "# Split data into training set and test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
        "\n",
        "# Train adecision tree model\n",
        "print('Training a decision tree model...')\n",
        "model = DecisionTreeClassifier().fit(X_train, y_train)\n",
        "\n",
        "# Calculate accuracy\n",
        "y_hat = model.predict(X_test)\n",
        "acc = np.average(y_hat == y_test)\n",
        "print('Accuracy:', acc)\n",
        "run.log('Accuracy', np.float(acc))\n",
        "\n",
        "# Calculate AUC\n",
        "y_scores = model.predict_proba(X_test)\n",
        "auc = roc_auc_score(y_test,y_scores[:,1])\n",
        "print('AUC: ' + str(auc))\n",
        "run.log('AUC', np.float(auc))\n",
        "\n",
        "# Plot ROC curve\n",
        "fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])\n",
        "fig = plt.figure(figsize=(6, 4))\n",
        "# Plot the diagonal 50% line\n",
        "plt.plot([0, 1], [0, 1], 'k--')\n",
        "# Plot the FPR and TPR achieved by our model\n",
        "plt.plot(fpr, tpr)\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "run.log_image(name = \"ROC\", plot = fig)\n",
        "plt.show()\n",
        "\n",
        "# Save the trained model in the outputs folder\n",
        "print(\"Saving model...\")\n",
        "os.makedirs('outputs', exist_ok=True)\n",
        "model_file = os.path.join('outputs', 'diabetes_model.pkl')\n",
        "joblib.dump(value=model, filename=model_file)\n",
        "\n",
        "# Register the model\n",
        "print('Registering model...')\n",
        "Model.register(workspace=run.experiment.workspace,\n",
        "               model_path = model_file,\n",
        "               model_name = 'diabetes_model',\n",
        "               tags={'Training context':'Pipeline'},\n",
        "               properties={'AUC': np.float(auc), 'Accuracy': np.float(acc)})\n",
        "\n",
        "\n",
        "run.complete()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting diabetes_pipeline/train_diabetes.py\n"
          ]
        }
      ],
      "execution_count": 12,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assign the compute target"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "\n",
        "cluster_name = \"ac-aml\"\n",
        "\n",
        "try:\n",
        "    # Check for existing compute target\n",
        "    pipeline_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
        "    print('Found existing cluster, use it.')\n",
        "except ComputeTargetException:\n",
        "    # If it doesn't already exist, create it\n",
        "    try:\n",
        "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
        "        pipeline_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
        "        pipeline_cluster.wait_for_completion(show_output=True)\n",
        "    except Exception as ex:\n",
        "        print(ex)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing cluster, use it.\n"
          ]
        }
      ],
      "execution_count": 13,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1621349909799
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ensure the necessary packages are installed on your compute"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Environment\n",
        "from azureml.core.conda_dependencies import CondaDependencies\n",
        "from azureml.core.runconfig import RunConfiguration\n",
        "\n",
        "# Create a Python environment for the experiment\n",
        "diabetes_env = Environment(\"diabetes-pipeline-env\")\n",
        "\n",
        "# Create a set of package dependencies\n",
        "diabetes_packages = CondaDependencies.create(conda_packages=['scikit-learn','ipykernel','matplotlib','pandas','pip'],\n",
        "                                             pip_packages=['azureml-defaults','azureml-dataprep[pandas]','pyarrow'])\n",
        "\n",
        "# Add the dependencies to the environment\n",
        "diabetes_env.python.conda_dependencies = diabetes_packages\n",
        "\n",
        "# Register the environment \n",
        "diabetes_env.register(workspace=ws)\n",
        "registered_env = Environment.get(ws, 'diabetes-pipeline-env')\n",
        "\n",
        "# Create a new runconfig object for the pipeline\n",
        "pipeline_run_config = RunConfiguration()\n",
        "\n",
        "# Use the compute you created above. \n",
        "pipeline_run_config.target = pipeline_cluster\n",
        "\n",
        "# Assign the environment to the run configuration\n",
        "pipeline_run_config.environment = registered_env\n",
        "\n",
        "print (\"Run configuration created.\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run configuration created.\n"
          ]
        }
      ],
      "execution_count": 14,
      "metadata": {
        "gather": {
          "logged": 1621349978156
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the pipeline"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core import PipelineData\n",
        "from azureml.pipeline.steps import PythonScriptStep\n",
        "\n",
        "# Get the training dataset\n",
        "diabetes_ds = ws.datasets.get(\"diabetes dataset\")\n",
        "\n",
        "# Create a PipelineData for the model folder\n",
        "prepped_data_folder = PipelineData(\"prepped_data_folder\", datastore=ws.get_default_datastore())\n",
        "\n",
        "# Step 1: Run the data prep script\n",
        "prep_step = PythonScriptStep(name = \"Prepare Data\",\n",
        "                                source_directory = experiment_folder,\n",
        "                                script_name = \"prep_diabetes.py\",\n",
        "                                arguments = ['--input-data', diabetes_ds.as_named_input('raw_data'),\n",
        "                                             '--prepped-data', prepped_data_folder],\n",
        "                                outputs=[prepped_data_folder],\n",
        "                                compute_target = pipeline_cluster,\n",
        "                                runconfig = pipeline_run_config,\n",
        "                                allow_reuse = True)\n",
        "\n",
        "# Step 2: Run the training script\n",
        "train_step = PythonScriptStep(name = \"Train and Register Model\",\n",
        "                                source_directory = experiment_folder,\n",
        "                                script_name = \"train_diabetes.py\",\n",
        "                                arguments = ['--training-folder', prepped_data_folder],\n",
        "                                inputs=[prepped_data_folder],\n",
        "                                compute_target = pipeline_cluster,\n",
        "                                runconfig = pipeline_run_config,\n",
        "                                allow_reuse = True)\n",
        "\n",
        "print(\"Pipeline steps defined\")"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline steps defined\n"
          ]
        }
      ],
      "execution_count": 15,
      "metadata": {
        "gather": {
          "logged": 1621350018137
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the pipeline from the defined steps"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment\n",
        "from azureml.pipeline.core import Pipeline\n",
        "from azureml.widgets import RunDetails\n",
        "\n",
        "# Construct the pipeline\n",
        "pipeline_steps = [prep_step, train_step]\n",
        "pipeline = Pipeline(workspace=ws, steps=pipeline_steps)\n",
        "print(\"Pipeline is built.\")\n",
        "\n",
        "# Create an experiment and run the pipeline\n",
        "experiment = Experiment(workspace=ws, name = 'mslearn-diabetes-pipeline')\n",
        "pipeline_run = experiment.submit(pipeline, regenerate_outputs=True)\n",
        "print(\"Pipeline submitted for execution.\")\n",
        "RunDetails(pipeline_run).show()\n",
        "pipeline_run.wait_for_completion(show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline is built.\n",
            "Created step Prepare Data [b30ff547][9b56d1e0-5d20-4a99-8c82-4444010bfd1b], (This step will run and generate new outputs)Created step Train and Register Model [b0be7842][0f96d972-d4ff-454d-bb1b-a5d35331c7d3], (This step will run and generate new outputs)\n",
            "\n",
            "Submitted PipelineRun 047ec2f9-08ed-48b0-b903-f4695490d92f\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/047ec2f9-08ed-48b0-b903-f4695490d92f?wsid=/subscriptions/b7bf924e-67c3-4e5b-a5a7-3a2988311e4c/resourcegroups/dp-100/workspaces/lkftest&tid=e54f6a3d-b8e3-4e00-bbbf-c7a65d1e76b0\n",
            "Pipeline submitted for execution.\n",
            "PipelineRunId: 047ec2f9-08ed-48b0-b903-f4695490d92f\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/047ec2f9-08ed-48b0-b903-f4695490d92f?wsid=/subscriptions/b7bf924e-67c3-4e5b-a5a7-3a2988311e4c/resourcegroups/dp-100/workspaces/lkftest&tid=e54f6a3d-b8e3-4e00-bbbf-c7a65d1e76b0\n",
            "PipelineRun Status: NotStarted\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "_PipelineWidget(widget_settings={'childWidgetDisplay': 'popup', 'send_telemetry': False, 'log_level': 'INFO', …",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9074c88a1d3f478b91068a50ab1518f7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/aml.mini.widget.v1": "{\"status\": \"Completed\", \"workbench_run_details_uri\": \"https://ml.azure.com/runs/047ec2f9-08ed-48b0-b903-f4695490d92f?wsid=/subscriptions/b7bf924e-67c3-4e5b-a5a7-3a2988311e4c/resourcegroups/dp-100/workspaces/lkftest&tid=e54f6a3d-b8e3-4e00-bbbf-c7a65d1e76b0\", \"run_id\": \"047ec2f9-08ed-48b0-b903-f4695490d92f\", \"run_properties\": {\"run_id\": \"047ec2f9-08ed-48b0-b903-f4695490d92f\", \"created_utc\": \"2021-05-18T15:00:34.321449Z\", \"properties\": {\"azureml.runsource\": \"azureml.PipelineRun\", \"runSource\": \"SDK\", \"runType\": \"SDK\", \"azureml.parameters\": \"{}\"}, \"tags\": {\"azureml.pipelineComponent\": \"pipelinerun\"}, \"end_time_utc\": \"2021-05-18T15:02:30.681171Z\", \"status\": \"Completed\", \"log_files\": {\"logs/azureml/executionlogs.txt\": \"https://lkftest7730197733.blob.core.windows.net/azureml/ExperimentRun/dcid.047ec2f9-08ed-48b0-b903-f4695490d92f/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=Wll6Y0yxxxobd%2FzwFLXFa4nsapxAN10WtQibWogbXJw%3D&st=2021-05-18T15%3A51%3A36Z&se=2021-05-19T00%3A01%3A36Z&sp=r\", \"logs/azureml/stderrlogs.txt\": \"https://lkftest7730197733.blob.core.windows.net/azureml/ExperimentRun/dcid.047ec2f9-08ed-48b0-b903-f4695490d92f/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=NYY1K6jE7IsbGtDI08DBDV5XueHa%2FyfjJniXQ0nIRV0%3D&st=2021-05-18T15%3A51%3A36Z&se=2021-05-19T00%3A01%3A36Z&sp=r\", \"logs/azureml/stdoutlogs.txt\": \"https://lkftest7730197733.blob.core.windows.net/azureml/ExperimentRun/dcid.047ec2f9-08ed-48b0-b903-f4695490d92f/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=Rfp7TeEG5wykbP3WbAAiv9Xujy3GT3ZnICKxRT2E43Q%3D&st=2021-05-18T15%3A51%3A36Z&se=2021-05-19T00%3A01%3A36Z&sp=r\"}, \"log_groups\": [[\"logs/azureml/executionlogs.txt\", \"logs/azureml/stderrlogs.txt\", \"logs/azureml/stdoutlogs.txt\"]], \"run_duration\": \"0:01:56\", \"run_number\": \"1621350034\", \"run_queued_details\": {\"status\": \"Finished\", \"details\": null}}, \"child_runs\": [{\"run_id\": \"8b7674e5-b587-4fac-aeff-7b0d59fc577e\", \"name\": \"Prepare Data\", \"status\": \"Finished\", \"start_time\": \"2021-05-18T15:00:49.123966Z\", \"created_time\": \"2021-05-18T15:00:37.33398Z\", \"end_time\": \"2021-05-18T15:01:40.10014Z\", \"duration\": \"0:01:02\", \"run_number\": 1621350037, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-05-18T15:00:37.33398Z\", \"is_reused\": \"\"}, {\"run_id\": \"0def4b27-451d-4e2e-8940-1c40bf6dfc01\", \"name\": \"Train and Register Model\", \"status\": \"Finished\", \"start_time\": \"2021-05-18T15:01:54.950093Z\", \"created_time\": \"2021-05-18T15:01:41.576757Z\", \"end_time\": \"2021-05-18T15:02:29.548775Z\", \"duration\": \"0:00:47\", \"run_number\": 1621350101, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-05-18T15:01:41.576757Z\", \"is_reused\": \"\"}], \"children_metrics\": {\"categories\": null, \"series\": null, \"metricName\": null}, \"run_metrics\": [], \"run_logs\": \"[2021-05-18 15:00:37Z] Submitting 1 runs, first five are: b30ff547:8b7674e5-b587-4fac-aeff-7b0d59fc577e\\n[2021-05-18 15:01:41Z] Completing processing run id 8b7674e5-b587-4fac-aeff-7b0d59fc577e.\\n[2021-05-18 15:01:41Z] Submitting 1 runs, first five are: b0be7842:0def4b27-451d-4e2e-8940-1c40bf6dfc01\\n[2021-05-18 15:02:30Z] Completing processing run id 0def4b27-451d-4e2e-8940-1c40bf6dfc01.\\n\\nRun is completed.\", \"graph\": {\"datasource_nodes\": {\"86824cee\": {\"node_id\": \"86824cee\", \"name\": \"diabetes dataset\"}}, \"module_nodes\": {\"b30ff547\": {\"node_id\": \"b30ff547\", \"name\": \"Prepare Data\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"8b7674e5-b587-4fac-aeff-7b0d59fc577e\"}, \"b0be7842\": {\"node_id\": \"b0be7842\", \"name\": \"Train and Register Model\", \"status\": \"Finished\", \"_is_reused\": false, \"run_id\": \"0def4b27-451d-4e2e-8940-1c40bf6dfc01\"}}, \"edges\": [{\"source_node_id\": \"86824cee\", \"source_node_name\": \"diabetes dataset\", \"source_name\": \"data\", \"target_name\": \"raw_data\", \"dst_node_id\": \"b30ff547\", \"dst_node_name\": \"Prepare Data\"}, {\"source_node_id\": \"b30ff547\", \"source_node_name\": \"Prepare Data\", \"source_name\": \"prepped_data_folder\", \"target_name\": \"prepped_data_folder\", \"dst_node_id\": \"b0be7842\", \"dst_node_name\": \"Train and Register Model\"}], \"child_runs\": [{\"run_id\": \"8b7674e5-b587-4fac-aeff-7b0d59fc577e\", \"name\": \"Prepare Data\", \"status\": \"Finished\", \"start_time\": \"2021-05-18T15:00:49.123966Z\", \"created_time\": \"2021-05-18T15:00:37.33398Z\", \"end_time\": \"2021-05-18T15:01:40.10014Z\", \"duration\": \"0:01:02\", \"run_number\": 1621350037, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-05-18T15:00:37.33398Z\", \"is_reused\": \"\"}, {\"run_id\": \"0def4b27-451d-4e2e-8940-1c40bf6dfc01\", \"name\": \"Train and Register Model\", \"status\": \"Finished\", \"start_time\": \"2021-05-18T15:01:54.950093Z\", \"created_time\": \"2021-05-18T15:01:41.576757Z\", \"end_time\": \"2021-05-18T15:02:29.548775Z\", \"duration\": \"0:00:47\", \"run_number\": 1621350101, \"metric\": null, \"run_type\": \"azureml.StepRun\", \"training_percent\": null, \"created_time_dt\": \"2021-05-18T15:01:41.576757Z\", \"is_reused\": \"\"}]}, \"widget_settings\": {\"childWidgetDisplay\": \"popup\", \"send_telemetry\": false, \"log_level\": \"INFO\", \"sdk_version\": \"1.27.0\"}, \"loading\": false}"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PipelineRun Status: Running\n",
            "\n",
            "\n",
            "StepRunId: 8b7674e5-b587-4fac-aeff-7b0d59fc577e\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/8b7674e5-b587-4fac-aeff-7b0d59fc577e?wsid=/subscriptions/b7bf924e-67c3-4e5b-a5a7-3a2988311e4c/resourcegroups/dp-100/workspaces/lkftest&tid=e54f6a3d-b8e3-4e00-bbbf-c7a65d1e76b0\n",
            "StepRun( Prepare Data ) Status: Running\n",
            "\n",
            "Streaming azureml-logs/55_azureml-execution-tvmps_b8452806c64ead682d779f49c85ab1dde905589d561602cce286aa7980a922bd_d.txt\n",
            "========================================================================================================================\n",
            "2021-05-18T15:00:48Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/mounts/workspaceblobstore\n",
            "2021-05-18T15:00:49Z Starting output-watcher...\n",
            "2021-05-18T15:00:49Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
            "2021-05-18T15:00:49Z Executing 'Copy ACR Details file' on 10.0.0.5\n",
            "2021-05-18T15:00:49Z Copy ACR Details file succeeded on 10.0.0.5. Output: \n",
            ">>>   \n",
            ">>>   \n",
            "Login Succeeded\n",
            "Using default tag: latest\n",
            "latest: Pulling from azureml/azureml_443e6f417ae4fd3295e21acd32219350\n",
            "Digest: sha256:9b0f5eccbd45f901e8ed5166f10b79cc561983676cbd378df967ed32d93de5c7\n",
            "Status: Image is up to date for 3d8c8017d49a4265abf7f2d185cffa18.azurecr.io/azureml/azureml_443e6f417ae4fd3295e21acd32219350:latest\n",
            "3d8c8017d49a4265abf7f2d185cffa18.azurecr.io/azureml/azureml_443e6f417ae4fd3295e21acd32219350:latest\n",
            "2021-05-18T15:00:51Z Check if container 8b7674e5-b587-4fac-aeff-7b0d59fc577e already exist exited with 0, \n",
            "\n",
            "9773c0f1d6d27eb7e9baeabafe1bfa3743e5ffc11c3c989d3580f3a3e843a3b7\n",
            "2021-05-18T15:00:52Z Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
            "2021-05-18T15:00:52Z containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-48d4b33f4028511f87a0da2982bb8cbe-9ed3cbc5bbb445e7-01 -sshRequired=false] \n",
            "2021/05/18 15:00:52 Starting App Insight Logger for task:  containerSetup\n",
            "2021/05/18 15:00:52 Version: 3.0.01597.0004 Branch: 2021-05-17-bing-hotfix Commit: 974f3e4\n",
            "2021/05/18 15:00:52 Entered ContainerSetupTask - Preparing infiniband\n",
            "2021/05/18 15:00:52 Starting infiniband setup\n",
            "2021/05/18 15:00:52 Python Version found is Python 3.6.2 :: Anaconda, Inc.\n",
            "\n",
            "2021/05/18 15:00:52 Returning Python Version as 3.6\n",
            "2021/05/18 15:00:52 VMSize: standard_ds3_v2, Host: ubuntu-18, Container: ubuntu-16.04\n",
            "2021/05/18 15:00:52 VMSize: standard_ds3_v2, Host: ubuntu-18, Container: ubuntu-16.04\n",
            "2021-05-18T15:00:52Z VMSize: standard_ds3_v2, Host: ubuntu-18, Container: ubuntu-16.04\n",
            "2021/05/18 15:00:52 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
            "2021/05/18 15:00:52 Not setting up Infiniband in Container\n",
            "2021/05/18 15:00:52 Not setting up Infiniband in Container\n",
            "2021-05-18T15:00:52Z Not setting up Infiniband in Container\n",
            "2021/05/18 15:00:52 Python Version found is Python 3.6.2 :: Anaconda, Inc.\n",
            "\n",
            "2021/05/18 15:00:52 Returning Python Version as 3.6\n",
            "2021/05/18 15:00:52 sshd inside container not required for job, skipping setup.\n",
            "2021/05/18 15:00:53 All App Insights Logs was send successfully\n",
            "2021/05/18 15:00:53 App Insight Client has already been closed\n",
            "2021/05/18 15:00:53 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
            "Stopped: false\n",
            "OriginalData: 1\n",
            "FilteredData: 0.\n",
            "2021-05-18T15:00:53Z Starting docker container succeeded.\n",
            "2021-05-18T15:01:01Z Job environment preparation succeeded on 10.0.0.5. Output: \n",
            ">>>   2021/05/18 15:00:47 Starting App Insight Logger for task:  prepareJobEnvironment\n",
            ">>>   2021/05/18 15:00:47 Version: 3.0.01597.0004 Branch: 2021-05-17-bing-hotfix Commit: 974f3e4\n",
            ">>>   2021/05/18 15:00:47 runtime.GOOS linux\n",
            ">>>   2021/05/18 15:00:47 Checking if '/tmp' exists\n",
            ">>>   2021/05/18 15:00:47 Reading dyanamic configs\n",
            ">>>   2021/05/18 15:00:47 Container sas url: https://baiscriptseastusprod.blob.core.windows.net/aihosttools?sv=2018-03-28&sr=c&si=aihosttoolspolicy&sig=gCpFfTbL8hPl%2BzV43hBdfOZC4SuKqZoJraIo10S4%2FYw%3D\n",
            ">>>   2021/05/18 15:00:47 Failed to read from file /mnt/batch/tasks/startup/wd/az_resource/xdsenv.variable/azsecpack.variables, open /mnt/batch/tasks/startup/wd/az_resource/xdsenv.variable/azsecpack.variables: no such file or directory\n",
            ">>>   2021/05/18 15:00:47 [in autoUpgradeFromJobNodeSetup] Is Azsecpack installer on host: false. Is Azsecpack enabled: false,\n",
            ">>>   2021/05/18 15:00:47 Starting Azsecpack installation on machine: lkftest#e54f6a3d-b8e3-4e00-bbbf-c7a65d1e76b0#b7bf924e-67c3-4e5b-a5a7-3a2988311e4c#dp-100#lkftest#lkftest\n",
            ">>>   2021/05/18 15:00:47 Is Azsecpack enabled: false, GetDisableVsatlsscan: true\n",
            ">>>   2021/05/18 15:00:47 Turning off azsecpack, if it is already running\n",
            ">>>   2021/05/18 15:00:47 [doTurnOffAzsecpack] output:Unit mdsd.service could not be found.\n",
            ">>>   ,err:exit status 1.\n",
            ">>>   2021/05/18 15:00:47 OS patching disabled by dynamic configs. Skipping.\n",
            ">>>   2021/05/18 15:00:47 Job: AZ_BATCHAI_JOB_NAME does not turn on the DetonationChamber\n",
            ">>>   2021/05/18 15:00:47 Start to getting gpu count by running nvidia-smi command\n",
            ">>>   2021/05/18 15:00:47 GPU count found on the node: 0\n",
            ">>>   2021/05/18 15:00:47 AMLComputeXDSEndpoint:  https://eastus-prodk8ds.batchai.core.windows.net\n",
            ">>>   2021/05/18 15:00:47 AMLComputeXDSApiVersion:  2018-02-01\n",
            ">>>   2021/05/18 15:00:47 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/config\n",
            ">>>   2021/05/18 15:00:47 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/wd\n",
            ">>>   2021/05/18 15:00:47 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/shared\n",
            ">>>   2021/05/18 15:00:47 From the policy service, the filtering patterns is: , data store is \n",
            ">>>   2021/05/18 15:00:47 Mounting job level file systems\n",
            ">>>   2021/05/18 15:00:47 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/mounts\n",
            ">>>   2021/05/18 15:00:47 Attempting to read datastore credentials file: /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/config/.amlcompute.datastorecredentials\n",
            ">>>   2021/05/18 15:00:47 Datastore credentials file not found, skipping.\n",
            ">>>   2021/05/18 15:00:47 Attempting to read runtime sas tokens file: /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/config/.master.runtimesastokens\n",
            ">>>   2021/05/18 15:00:47 Runtime sas tokens file not found, skipping.\n",
            ">>>   2021/05/18 15:00:47 No NFS configured\n",
            ">>>   2021/05/18 15:00:47 No Azure File Shares configured\n",
            ">>>   2021/05/18 15:00:47 Mounting blob file systems\n",
            ">>>   2021/05/18 15:00:47 Blobfuse runtime version 1.3.6\n",
            ">>>   2021/05/18 15:00:47 Mounting azureml-blobstore-3d8c8017-d49a-4265-abf7-f2d185cffa18 container from lkftest7730197733 account at /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/mounts/workspaceblobstore\n",
            ">>>   2021/05/18 15:00:47 Error opening env file:  open /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/config/.batchai.IdentityResponder.envlist: no such file or directory\n",
            ">>>   2021/05/18 15:00:47 Using Compute Identity to authenticate Blobfuse: false.\n",
            ">>>   2021/05/18 15:00:47 Using Compute Identity to authenticate Blobfuse: false.\n",
            ">>>   2021/05/18 15:00:47 Blobfuse cache size set to 24545 MB.\n",
            ">>>   2021/05/18 15:00:47 Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/caches/workspaceblobstore --file-cache-timeout-in-seconds=1000000 --cache-size-mb=24545 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
            ">>>   2021/05/18 15:00:47 Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/mounts/workspaceblobstore\n",
            ">>>   2021/05/18 15:00:49 Waiting for blobfs to be mounted at /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/mounts/workspaceblobstore\n",
            ">>>   2021/05/18 15:00:49 Successfully mounted azureml-blobstore-3d8c8017-d49a-4265-abf7-f2d185cffa18 container from lkftest7730197733 account at /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/mounts/workspaceblobstore\n",
            ">>>   2021/05/18 15:00:49 Created run_id directory: /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/mounts/workspaceblobstore/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e\n",
            ">>>   2021/05/18 15:00:49 No unmanaged file systems configured\n",
            ">>>   2021/05/18 15:00:49 Start to getting gpu count by running nvidia-smi command\n",
            ">>>   2021/05/18 15:00:49 From the policy service, the filtering patterns is: , data store is \n",
            ">>>   2021/05/18 15:00:49 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/mounts/workspaceblobstore/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/azureml_compute_logs\n",
            ">>>   2021/05/18 15:00:49 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/mounts/workspaceblobstore/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/logs\n",
            ">>>   2021/05/18 15:00:49 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/mounts/workspaceblobstore/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/outputs\n",
            ">>>   2021/05/18 15:00:49 Starting output-watcher...\n",
            ">>>   2021/05/18 15:00:49 Single file input dataset is enabled.\n",
            ">>>   2021/05/18 15:00:49 Start to pulling docker image: 3d8c8017d49a4265abf7f2d185cffa18.azurecr.io/azureml/azureml_443e6f417ae4fd3295e21acd32219350\n",
            ">>>   2021/05/18 15:00:49 Start pull docker image: 3d8c8017d49a4265abf7f2d185cffa18.azurecr.io\n",
            ">>>   2021/05/18 15:00:49 Getting credentials for image 3d8c8017d49a4265abf7f2d185cffa18.azurecr.io/azureml/azureml_443e6f417ae4fd3295e21acd32219350 with url 3d8c8017d49a4265abf7f2d185cffa18.azurecr.io\n",
            ">>>   2021/05/18 15:00:49 Container registry is ACR.\n",
            ">>>   2021/05/18 15:00:49 Skip getting ACR Credentials from Identity and will be getting it from EMS\n",
            ">>>   2021/05/18 15:00:49 Getting ACR Credentials from EMS for environment diabetes-pipeline-env:1\n",
            ">>>   2021/05/18 15:00:49 Requesting XDS for registry details.\n",
            ">>>   2021/05/18 15:00:49 Attempt 1 of http call to https://eastus-prodk8ds.batchai.core.windows.net/hosttoolapi/subscriptions/b7bf924e-67c3-4e5b-a5a7-3a2988311e4c/resourceGroups/dp-100/workspaces/lkftest/clusters/lkftest/nodes/tvmps_b8452806c64ead682d779f49c85ab1dde905589d561602cce286aa7980a922bd_d?api-version=2018-02-01\n",
            ">>>   2021/05/18 15:00:49 Got container registry details from credentials service for registry address: 3d8c8017d49a4265abf7f2d185cffa18.azurecr.io.\n",
            ">>>   2021/05/18 15:00:49 Writing ACR Details to file...\n",
            ">>>   2021/05/18 15:00:49 Copying ACR Details file to worker nodes...\n",
            ">>>   2021/05/18 15:00:49 Executing 'Copy ACR Details file' on 10.0.0.5\n",
            ">>>   2021/05/18 15:00:49 Begin executing 'Copy ACR Details file' task on Node\n",
            ">>>   2021/05/18 15:00:49 'Copy ACR Details file' task Node result: succeeded\n",
            ">>>   2021/05/18 15:00:49 Copy ACR Details file succeeded on 10.0.0.5. Output: \n",
            ">>>   >>>   \n",
            ">>>   >>>   \n",
            ">>>   2021/05/18 15:00:49 Successfully retrieved ACR Credentials from EMS.\n",
            ">>>   2021/05/18 15:00:49 EMS returned 3d8c8017d49a4265abf7f2d185cffa18.azurecr.io for environment diabetes-pipeline-env\n",
            ">>>   2021/05/18 15:00:49 Save docker credentials for image 3d8c8017d49a4265abf7f2d185cffa18.azurecr.io/azureml/azureml_443e6f417ae4fd3295e21acd32219350 in /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/wd/docker_login_E3D6F032F940C64F\n",
            ">>>   2021/05/18 15:00:49 start login to the docker registry\n",
            ">>>   2021/05/18 15:00:51 Successfully logged into the docker registry.\n",
            ">>>   2021/05/18 15:00:51 Start run pull docker image command\n",
            ">>>   2021/05/18 15:00:51 Pull docker image succeeded.\n",
            ">>>   2021/05/18 15:00:51 Removed docker config dir /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/wd/docker_login_E3D6F032F940C64F\n",
            ">>>   2021/05/18 15:00:51 Pull docker image time: 1.988326368s\n",
            ">>>   \n",
            ">>>   2021/05/18 15:00:51 Docker Version that this nodes use are: 20.10.6+azure\n",
            ">>>   \n",
            ">>>   2021/05/18 15:00:51 Start to getting gpu count by running nvidia-smi command\n",
            ">>>   2021/05/18 15:00:51 Setting the memory limit for docker container to be 13647 MB\n",
            ">>>   2021/05/18 15:00:51 The env variable file size is 40297 bytes\n",
            ">>>   2021/05/18 15:00:51 Creating parent cgroup '8b7674e5-b587-4fac-aeff-7b0d59fc577e' for Containers used in Job\n",
            ">>>   2021/05/18 15:00:51 Add parent cgroup '8b7674e5-b587-4fac-aeff-7b0d59fc577e' to container '8b7674e5-b587-4fac-aeff-7b0d59fc577e'\n",
            ">>>   2021/05/18 15:00:51 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
            ">>>   2021/05/18 15:00:51 Original Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,8b7674e5-b587-4fac-aeff-7b0d59fc577e,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/workitems/58005e7e-7554-49c5-b0d8-6052379f4cae/job-1/8b7674e5-b587-4fac-a_d4e5d66d-aa52-4b18-87fd-53d68532c992/certs:/mnt/batch/tasks/workitems/58005e7e-7554-49c5-b0d8-6052379f4cae/job-1/8b7674e5-b587-4fac-a_d4e5d66d-aa52-4b18-87fd-53d68532c992/certs,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,-m,13647m,-v,/mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/mounts/workspaceblobstore/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/mounts/workspaceblobstore/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/azureml_compute_logs,-v,/mnt/batch/tasks/workitems/58005e7e-7554-49c5-b0d8-6052379f4cae/job-1/8b7674e5-b587-4fac-a_d4e5d66d-aa52-4b18-87fd-53d68532c992/wd:/mnt/batch/tasks/workitems/58005e7e-7554-49c5-b0d8-6052379f4cae/job-1/8b7674e5-b587-4fac-a_d4e5d66d-aa52-4b18-87fd-53d68532c992/wd,-v,/mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e:/mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e,-v,/mnt/batch/tasks/shared/LS_root/shared/tracing/8b7674e5-b587-4fac-aeff-7b0d59fc577e/logs/azureml/tracing:/mnt/batch/tasks/shared/LS_root/shared/tracing/8b7674e5-b587-4fac-aeff-7b0d59fc577e/logs/azureml/tracing,-w,/mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/config/.batchai.envlist,--cgroup-parent=/8b7674e5-b587-4fac-aeff-7b0d59fc577e/,--shm-size,2g\n",
            ">>>   2021/05/18 15:00:51 the binding /mnt/batch/tasks/shared/LS_root/shared/tracing/8b7674e5-b587-4fac-aeff-7b0d59fc577e/logs/azureml/tracing:/mnt/batch/tasks/shared/LS_root/shared/tracing/8b7674e5-b587-4fac-aeff-7b0d59fc577e/logs/azureml/tracing is discarded as we already have /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared \n",
            ">>>   2021/05/18 15:00:51 the binding /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/mounts/workspaceblobstore/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/mounts/workspaceblobstore/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/azureml_compute_logs is discarded as we already have /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e:/mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e \n",
            ">>>   2021/05/18 15:00:51 Updated Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,8b7674e5-b587-4fac-aeff-7b0d59fc577e,-m,13647m,-w,/mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/config/.batchai.envlist,--cgroup-parent=/8b7674e5-b587-4fac-aeff-7b0d59fc577e/,--shm-size,2g,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e:/mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e,-v,/mnt/batch/tasks/workitems/58005e7e-7554-49c5-b0d8-6052379f4cae/job-1/8b7674e5-b587-4fac-a_d4e5d66d-aa52-4b18-87fd-53d68532c992/wd:/mnt/batch/tasks/workitems/58005e7e-7554-49c5-b0d8-6052379f4cae/job-1/8b7674e5-b587-4fac-a_d4e5d66d-aa52-4b18-87fd-53d68532c992/wd,-v,/mnt/batch/tasks/workitems/58005e7e-7554-49c5-b0d8-6052379f4cae/job-1/8b7674e5-b587-4fac-a_d4e5d66d-aa52-4b18-87fd-53d68532c992/certs:/mnt/batch/tasks/workitems/58005e7e-7554-49c5-b0d8-6052379f4cae/job-1/8b7674e5-b587-4fac-a_d4e5d66d-aa52-4b18-87fd-53d68532c992/certs\n",
            ">>>   2021/05/18 15:00:51 Running Docker command: docker run --ulimit memlock=9223372036854775807 --ulimit nofile=262144:262144 --cap-add sys_ptrace --name 8b7674e5-b587-4fac-aeff-7b0d59fc577e -m 13647m -w /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/wd --expose 23 --env-file /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/config/.batchai.envlist --cgroup-parent=/8b7674e5-b587-4fac-aeff-7b0d59fc577e/ --shm-size 2g -v /mnt/batch/tasks/startup:/mnt/batch/tasks/startup -v /mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared -v /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared -v /mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs -v /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e:/mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e -v /mnt/batch/tasks/workitems/58005e7e-7554-49c5-b0d8-6052379f4cae/job-1/8b7674e5-b587-4fac-a_d4e5d66d-aa52-4b18-87fd-53d68532c992/wd:/mnt/batch/tasks/workitems/58005e7e-7554-49c5-b0d8-6052379f4cae/job-1/8b7674e5-b587-4fac-a_d4e5d66d-aa52-4b18-87fd-53d68532c992/wd -v /mnt/batch/tasks/workitems/58005e7e-7554-49c5-b0d8-6052379f4cae/job-1/8b7674e5-b587-4fac-a_d4e5d66d-aa52-4b18-87fd-53d68532c992/certs:/mnt/batch/tasks/workitems/58005e7e-7554-49c5-b0d8-6052379f4cae/job-1/8b7674e5-b587-4fac-a_d4e5d66d-aa52-4b18-87fd-53d68532c992/certs -d -it --privileged --net=host 3d8c8017d49a4265abf7f2d185cffa18.azurecr.io/azureml/azureml_443e6f417ae4fd3295e21acd32219350\n",
            ">>>   2021/05/18 15:00:51 Check if container 8b7674e5-b587-4fac-aeff-7b0d59fc577e already exist exited with 0, \n",
            ">>>   \n",
            ">>>   2021/05/18 15:00:51 Check if container 8b7674e5-b587-4fac-aeff-7b0d59fc577e already exist exited with 0, \n",
            ">>>   \n",
            ">>>   2021/05/18 15:00:52 Attempt 1 of http call to https://eastus.api.azureml.ms/history/v1.0/private/subscriptions/b7bf924e-67c3-4e5b-a5a7-3a2988311e4c/resourceGroups/dp-100/providers/Microsoft.MachineLearningServices/workspaces/lkftest/runs/8b7674e5-b587-4fac-aeff-7b0d59fc577e/spans\n",
            ">>>   2021/05/18 15:00:52 Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
            ">>>   2021/05/18 15:00:52 Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
            ">>>   2021/05/18 15:00:52 containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-48d4b33f4028511f87a0da2982bb8cbe-9ed3cbc5bbb445e7-01 -sshRequired=false] \n",
            ">>>   2021/05/18 15:00:52 containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-48d4b33f4028511f87a0da2982bb8cbe-9ed3cbc5bbb445e7-01 -sshRequired=false] \n",
            ">>>   2021/05/18 15:00:53 Container ssh is not required for job type.\n",
            ">>>   2021/05/18 15:00:53 Starting docker container succeeded.\n",
            ">>>   2021/05/18 15:00:53 Starting docker container succeeded.\n",
            ">>>   2021/05/18 15:00:53 Disk space after starting docker container: 25999MB\n",
            ">>>   2021/05/18 15:00:53 Begin execution of runSpecialJobTask\n",
            ">>>   2021/05/18 15:00:53 runSpecialJobTask: os.GetEnv constants.StdouterrDir: /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/mounts/workspaceblobstore/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/azureml_compute_logs\n",
            ">>>   2021/05/18 15:00:53 runSpecialJobTask: Raw cmd for preparation is passed is: /azureml-envs/azureml_28b0d742a4cb5c02a5befb218632cd1a/bin/python /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/mounts/workspaceblobstore/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"8510d385-f92b-4469-b7e4-5f7ffc3c9021\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
            ">>>   2021/05/18 15:00:53 runSpecialJobTask: stdout path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/mounts/workspaceblobstore/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/azureml_compute_logs/65_job_prep-tvmps_b8452806c64ead682d779f49c85ab1dde905589d561602cce286aa7980a922bd_d.txt\n",
            ">>>   2021/05/18 15:00:53 runSpecialJobTask: stderr path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/mounts/workspaceblobstore/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/azureml_compute_logs/65_job_prep-tvmps_b8452806c64ead682d779f49c85ab1dde905589d561602cce286aa7980a922bd_d.txt\n",
            ">>>   2021/05/18 15:00:53 native cmd: export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/58005e7e-7554-49c5-b0d8-6052379f4cae/job-1/8b7674e5-b587-4fac-a_d4e5d66d-aa52-4b18-87fd-53d68532c992/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/mounts/workspaceblobstore/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e;/azureml-envs/azureml_28b0d742a4cb5c02a5befb218632cd1a/bin/python /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/mounts/workspaceblobstore/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"8510d385-f92b-4469-b7e4-5f7ffc3c9021\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
            ">>>   2021/05/18 15:00:53 runSpecialJobTask: commons.GetOsPlatform(): ubuntu\n",
            ">>>   2021/05/18 15:00:53 runSpecialJobTask: Running cmd: /usr/bin/docker exec -e AZUREML_SDK_TRACEPARENT=00-48d4b33f4028511f87a0da2982bb8cbe-6a72334c83120354-01 -t 8b7674e5-b587-4fac-aeff-7b0d59fc577e bash -c source /etc/bash.bashrc; PATH=$PATH:$AZ_BATCH_NODE_STARTUP_DIR/wd/;export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/58005e7e-7554-49c5-b0d8-6052379f4cae/job-1/8b7674e5-b587-4fac-a_d4e5d66d-aa52-4b18-87fd-53d68532c992/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/mounts/workspaceblobstore/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e;/azureml-envs/azureml_28b0d742a4cb5c02a5befb218632cd1a/bin/python /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/mounts/workspaceblobstore/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"8510d385-f92b-4469-b7e4-5f7ffc3c9021\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
            ">>>   2021/05/18 15:00:57 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
            ">>>   Stopped: false\n",
            ">>>   OriginalData: 1\n",
            ">>>   FilteredData: 0.\n",
            ">>>   2021/05/18 15:01:01 runSpecialJobTask: job preparation exited with code 0 and err <nil>\n",
            ">>>   \n",
            ">>>   2021/05/18 15:01:01 runSpecialJobTask: preparation: [2021-05-18T15:00:54.453087] Entering job preparation.\n",
            ">>>   2021/05/18 15:01:01 runSpecialJobTask: preparation: [2021-05-18T15:00:58.555101] Starting job preparation.\n",
            ">>>   2021/05/18 15:01:01 runSpecialJobTask: preparation: [2021-05-18T15:00:58.555148] Extracting the control code.\n",
            ">>>   2021/05/18 15:01:01 runSpecialJobTask: preparation: [2021-05-18T15:00:58.618277] fetching and extracting the control code on master node.\n",
            ">>>   2021/05/18 15:01:01 runSpecialJobTask: preparation: [2021-05-18T15:00:58.618358] Starting extract_project.\n",
            ">>>   2021/05/18 15:01:01 runSpecialJobTask: preparation: [2021-05-18T15:00:58.618470] Starting to extract zip file.\n",
            ">>>   2021/05/18 15:01:01 runSpecialJobTask: preparation: [2021-05-18T15:00:59.068108] Finished extracting zip file.\n",
            ">>>   2021/05/18 15:01:01 runSpecialJobTask: preparation: [2021-05-18T15:00:59.224503] Using urllib.request Python 3.0 or later\n",
            ">>>   2021/05/18 15:01:01 runSpecialJobTask: preparation: [2021-05-18T15:00:59.224554] Start fetching snapshots.\n",
            ">>>   2021/05/18 15:01:01 runSpecialJobTask: preparation: [2021-05-18T15:00:59.224602] Start fetching snapshot.\n",
            ">>>   2021/05/18 15:01:01 runSpecialJobTask: preparation: [2021-05-18T15:00:59.224612] Retrieving project from snapshot: 8510d385-f92b-4469-b7e4-5f7ffc3c9021\n",
            ">>>   2021/05/18 15:01:01 runSpecialJobTask: preparation: Starting the daemon thread to refresh tokens in background for process with pid = 46\n",
            ">>>   2021/05/18 15:01:01 runSpecialJobTask: preparation: [2021-05-18T15:00:59.505899] Finished fetching snapshot.\n",
            ">>>   2021/05/18 15:01:01 runSpecialJobTask: preparation: [2021-05-18T15:00:59.505932] Finished fetching snapshots.\n",
            ">>>   2021/05/18 15:01:01 runSpecialJobTask: preparation: [2021-05-18T15:00:59.505948] Finished extract_project.\n",
            ">>>   2021/05/18 15:01:01 runSpecialJobTask: preparation: [2021-05-18T15:00:59.515879] Finished fetching and extracting the control code.\n",
            ">>>   2021/05/18 15:01:01 runSpecialJobTask: preparation: [2021-05-18T15:00:59.519982] downloadDataStore - Download from datastores if requested.\n",
            ">>>   2021/05/18 15:01:01 runSpecialJobTask: preparation: [2021-05-18T15:00:59.520751] Start run_history_prep.\n",
            ">>>   2021/05/18 15:01:01 runSpecialJobTask: preparation: [2021-05-18T15:00:59.570338] Entering context manager injector.\n",
            ">>>   2021/05/18 15:01:01 runSpecialJobTask: preparation: Acquired lockfile /tmp/8b7674e5-b587-4fac-aeff-7b0d59fc577e-datastore.lock to downloading input data references\n",
            ">>>   2021/05/18 15:01:01 runSpecialJobTask: preparation: [2021-05-18T15:01:01.038551] downloadDataStore completed\n",
            ">>>   2021/05/18 15:01:01 runSpecialJobTask: preparation: [2021-05-18T15:01:01.041854] Job preparation is complete.\n",
            ">>>   2021/05/18 15:01:01 Execution of runSpecialJobTask completed\n",
            ">>>   2021/05/18 15:01:01 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
            ">>>   Stopped: false\n",
            ">>>   OriginalData: 3\n",
            ">>>   FilteredData: 0.\n",
            ">>>   2021/05/18 15:01:01 Process Exiting with Code:  0\n",
            ">>>   2021/05/18 15:01:01 All App Insights Logs was send successfully\n",
            ">>>   \n",
            "2021-05-18T15:01:01Z 127.0.0.1 slots=4 max-slots=4\n",
            "2021-05-18T15:01:02Z launching Custom job\n",
            "\n",
            "Streaming azureml-logs/70_driver_log.txt\n",
            "========================================\n",
            "2021/05/18 15:01:02 Starting App Insight Logger for task:  runTaskLet\n",
            "2021/05/18 15:01:02 Attempt 1 of http call to http://10.0.0.5:16384/sendlogstoartifacts/info\n",
            "2021/05/18 15:01:02 Attempt 1 of http call to http://10.0.0.5:16384/sendlogstoartifacts/status\n",
            "[2021-05-18T15:01:02.688973] Entering context manager injector.\n",
            "[context_manager_injector.py] Command line Options: Namespace(inject=['ProjectPythonPath:context_managers.ProjectPythonPath', 'RunHistory:context_managers.RunHistory', 'TrackUserError:context_managers.TrackUserError'], invocation=['prep_diabetes.py', '--input-data', 'fab63e74-fb2e-488c-bd51-d2dc5bfbed66', '--prepped-data', '/mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/mounts/workspaceblobstore/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/prepped_data_folder'])\n",
            "Script type = None\n",
            "[2021-05-18T15:01:04.128918] Entering Run History Context Manager.\n",
            "[2021-05-18T15:01:04.708014] Current directory: /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/mounts/workspaceblobstore/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e\n",
            "[2021-05-18T15:01:04.708281] Preparing to call script [prep_diabetes.py] with arguments:['--input-data', 'fab63e74-fb2e-488c-bd51-d2dc5bfbed66', '--prepped-data', '/mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/mounts/workspaceblobstore/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/prepped_data_folder']\n",
            "[2021-05-18T15:01:04.708332] After variable expansion, calling script [prep_diabetes.py] with arguments:['--input-data', 'fab63e74-fb2e-488c-bd51-d2dc5bfbed66', '--prepped-data', '/mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/mounts/workspaceblobstore/azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/prepped_data_folder']\n",
            "\n",
            "2021/05/18 15:01:07 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
            "Stopped: false\n",
            "OriginalData: 1\n",
            "FilteredData: 0.\n",
            "Loading Data...\n",
            "Saving Data...\n",
            "\n",
            "Streaming azureml-logs/75_job_post-tvmps_b8452806c64ead682d779f49c85ab1dde905589d561602cce286aa7980a922bd_d.txt\n",
            "===============================================================================================================\n",
            "[2021-05-18T15:01:30.079944] Entering job release\n",
            "[2021-05-18T15:01:31.113256] Starting job release\n",
            "[2021-05-18T15:01:31.113962] Logging experiment finalizing status in history service.\n",
            "[2021-05-18T15:01:31.114262] job release stage : upload_datastore starting...\n",
            "Starting the daemon thread to refresh tokens in background for process with pid = 339\n",
            "[2021-05-18T15:01:31.117687] job release stage : start importing azureml.history._tracking in run_history_release.\n",
            "[2021-05-18T15:01:31.124221] job release stage : copy_batchai_cached_logs starting...\n",
            "[2021-05-18T15:01:31.124341] job release stage : execute_job_release starting...\n",
            "[2021-05-18T15:01:31.124560] job release stage : copy_batchai_cached_logs completed...\n",
            "[2021-05-18T15:01:31.125803] Entering context manager injector.\n",
            "[2021-05-18T15:01:31.141973] job release stage : upload_datastore completed...\n",
            "[2021-05-18T15:01:31.263401] job release stage : execute_job_release completed...\n",
            "[2021-05-18T15:01:31.279966] job release stage : send_run_telemetry starting...\n",
            "[2021-05-18T15:01:31.419215] get vm size and vm region successfully.\n",
            "[2021-05-18T15:01:31.651449] get compute meta data successfully.\n",
            "[2021-05-18T15:01:31.852122] post artifact meta request successfully.\n",
            "[2021-05-18T15:01:31.876061] upload compute record artifact successfully.\n",
            "[2021-05-18T15:01:31.876168] job release stage : send_run_telemetry completed...\n",
            "[2021-05-18T15:01:31.876460] Job release is complete\n",
            "\n",
            "StepRun(Prepare Data) Execution Summary\n",
            "========================================\n",
            "StepRun( Prepare Data ) Status: Finished\n",
            "{'runId': '8b7674e5-b587-4fac-aeff-7b0d59fc577e', 'target': 'lkftest', 'status': 'Completed', 'startTimeUtc': '2021-05-18T15:00:49.123966Z', 'endTimeUtc': '2021-05-18T15:01:40.10014Z', 'properties': {'ContentSnapshotId': '8510d385-f92b-4469-b7e4-5f7ffc3c9021', 'StepType': 'PythonScriptStep', 'azureml.moduleid': '9b56d1e0-5d20-4a99-8c82-4444010bfd1b', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': 'b30ff547', 'azureml.pipelinerunid': '047ec2f9-08ed-48b0-b903-f4695490d92f', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [{'dataset': {'id': 'fab63e74-fb2e-488c-bd51-d2dc5bfbed66'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'raw_data', 'mechanism': 'Direct'}}], 'outputDatasets': [], 'runDefinition': {'script': 'prep_diabetes.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--input-data', 'DatasetConsumptionConfig:raw_data', '--prepped-data', '$AZUREML_DATAREFERENCE_prepped_data_folder'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'lkftest', 'dataReferences': {'prepped_data_folder': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/prepped_data_folder', 'pathOnCompute': None, 'overwrite': False}}, 'data': {'raw_data': {'dataLocation': {'dataset': {'id': 'fab63e74-fb2e-488c-bd51-d2dc5bfbed66', 'name': None, 'version': '1'}, 'dataPath': None, 'uri': None}, 'mechanism': 'Direct', 'environmentVariableName': 'raw_data', 'pathOnCompute': None, 'overwrite': False}}, 'outputData': {}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'diabetes-pipeline-env', 'version': '1', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['azureml-defaults~=1.27.0', 'azureml-dataprep[pandas]', 'pyarrow']}, 'scikit-learn', 'ipykernel', 'matplotlib', 'pandas', 'pip'], 'name': 'azureml_28b0d742a4cb5c02a5befb218632cd1a'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210301.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'dockerContext': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': None, 'imageVersion': None, 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_b8452806c64ead682d779f49c85ab1dde905589d561602cce286aa7980a922bd_d.txt': 'https://lkftest7730197733.blob.core.windows.net/azureml/ExperimentRun/dcid.8b7674e5-b587-4fac-aeff-7b0d59fc577e/azureml-logs/55_azureml-execution-tvmps_b8452806c64ead682d779f49c85ab1dde905589d561602cce286aa7980a922bd_d.txt?sv=2019-02-02&sr=b&sig=mzSYdPshuigvGJ9jYVYEXfY7EVaU7w8JkCkDrDtZzKU%3D&st=2021-05-18T14%3A51%3A33Z&se=2021-05-18T23%3A01%3A33Z&sp=r', 'azureml-logs/65_job_prep-tvmps_b8452806c64ead682d779f49c85ab1dde905589d561602cce286aa7980a922bd_d.txt': 'https://lkftest7730197733.blob.core.windows.net/azureml/ExperimentRun/dcid.8b7674e5-b587-4fac-aeff-7b0d59fc577e/azureml-logs/65_job_prep-tvmps_b8452806c64ead682d779f49c85ab1dde905589d561602cce286aa7980a922bd_d.txt?sv=2019-02-02&sr=b&sig=CVZ0fjLwyCwo0rjEkkPszlbABUayjLQnB04PAKldFHc%3D&st=2021-05-18T14%3A51%3A33Z&se=2021-05-18T23%3A01%3A33Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://lkftest7730197733.blob.core.windows.net/azureml/ExperimentRun/dcid.8b7674e5-b587-4fac-aeff-7b0d59fc577e/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=zYmFqdIKGO2df4nXpzg1EVEtXXTXR3ioeC5bIWLUxsw%3D&st=2021-05-18T14%3A51%3A33Z&se=2021-05-18T23%3A01%3A33Z&sp=r', 'azureml-logs/75_job_post-tvmps_b8452806c64ead682d779f49c85ab1dde905589d561602cce286aa7980a922bd_d.txt': 'https://lkftest7730197733.blob.core.windows.net/azureml/ExperimentRun/dcid.8b7674e5-b587-4fac-aeff-7b0d59fc577e/azureml-logs/75_job_post-tvmps_b8452806c64ead682d779f49c85ab1dde905589d561602cce286aa7980a922bd_d.txt?sv=2019-02-02&sr=b&sig=lj1i4wz2HoVFDeshIzupVeVMQQDOHM%2Fy1pJNvWcRKsM%3D&st=2021-05-18T14%3A51%3A33Z&se=2021-05-18T23%3A01%3A33Z&sp=r', 'azureml-logs/process_info.json': 'https://lkftest7730197733.blob.core.windows.net/azureml/ExperimentRun/dcid.8b7674e5-b587-4fac-aeff-7b0d59fc577e/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=5RCUD2CZoh2fg1ewWWHubfootmnThDUIGyIBjikSlH8%3D&st=2021-05-18T14%3A51%3A33Z&se=2021-05-18T23%3A01%3A33Z&sp=r', 'azureml-logs/process_status.json': 'https://lkftest7730197733.blob.core.windows.net/azureml/ExperimentRun/dcid.8b7674e5-b587-4fac-aeff-7b0d59fc577e/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=XidaPibvae0TDuQWV2UbcctCKTMMmy3Umh2ae4ErVuw%3D&st=2021-05-18T14%3A51%3A33Z&se=2021-05-18T23%3A01%3A33Z&sp=r', 'logs/azureml/106_azureml.log': 'https://lkftest7730197733.blob.core.windows.net/azureml/ExperimentRun/dcid.8b7674e5-b587-4fac-aeff-7b0d59fc577e/logs/azureml/106_azureml.log?sv=2019-02-02&sr=b&sig=wPbV%2B41iZ8Gx3f2UaVHplz7DHRm%2FWvcu%2BUNK6uZ1pfo%3D&st=2021-05-18T14%3A51%3A33Z&se=2021-05-18T23%3A01%3A33Z&sp=r', 'logs/azureml/dataprep/backgroundProcess.log': 'https://lkftest7730197733.blob.core.windows.net/azureml/ExperimentRun/dcid.8b7674e5-b587-4fac-aeff-7b0d59fc577e/logs/azureml/dataprep/backgroundProcess.log?sv=2019-02-02&sr=b&sig=R577R1o5V5A4Flwq4J1rwv6ffnE7lYF1QfoFl%2BMhC14%3D&st=2021-05-18T14%3A51%3A33Z&se=2021-05-18T23%3A01%3A33Z&sp=r', 'logs/azureml/dataprep/backgroundProcess_Telemetry.log': 'https://lkftest7730197733.blob.core.windows.net/azureml/ExperimentRun/dcid.8b7674e5-b587-4fac-aeff-7b0d59fc577e/logs/azureml/dataprep/backgroundProcess_Telemetry.log?sv=2019-02-02&sr=b&sig=8BpVt6O9H1THQ%2BQu%2ByduQeSkPZ6RCboI9aANAerAEK8%3D&st=2021-05-18T14%3A51%3A33Z&se=2021-05-18T23%3A01%3A33Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://lkftest7730197733.blob.core.windows.net/azureml/ExperimentRun/dcid.8b7674e5-b587-4fac-aeff-7b0d59fc577e/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=MO72iOJKH%2Ff%2B6VfbqXFMr8hrJXZLAdgGDfZMFx9F3io%3D&st=2021-05-18T14%3A51%3A33Z&se=2021-05-18T23%3A01%3A33Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://lkftest7730197733.blob.core.windows.net/azureml/ExperimentRun/dcid.8b7674e5-b587-4fac-aeff-7b0d59fc577e/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=5vLDhPM474ApQiRLAoCHoruCen1uHxXeIGnKhp5zStw%3D&st=2021-05-18T14%3A51%3A33Z&se=2021-05-18T23%3A01%3A33Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://lkftest7730197733.blob.core.windows.net/azureml/ExperimentRun/dcid.8b7674e5-b587-4fac-aeff-7b0d59fc577e/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=2fyDBhaHDY2B1y2DqXDJzgdwS40PoSwKr3JYgp7N%2Fvg%3D&st=2021-05-18T14%3A51%3A33Z&se=2021-05-18T23%3A01%3A33Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://lkftest7730197733.blob.core.windows.net/azureml/ExperimentRun/dcid.8b7674e5-b587-4fac-aeff-7b0d59fc577e/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=EgGJr6Gt3%2Fj7qH5nPYCfL1DwmAOG1NxrakNx3%2BIGf5U%3D&st=2021-05-18T14%3A51%3A33Z&se=2021-05-18T23%3A01%3A33Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://lkftest7730197733.blob.core.windows.net/azureml/ExperimentRun/dcid.8b7674e5-b587-4fac-aeff-7b0d59fc577e/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=mRcYZ87RF9qgRG209yqvG06kkvNWtQ1PT0SPMhexodw%3D&st=2021-05-18T14%3A51%3A33Z&se=2021-05-18T23%3A01%3A33Z&sp=r'}, 'submittedBy': 'Landon Fowler'}\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "StepRunId: 0def4b27-451d-4e2e-8940-1c40bf6dfc01\n",
            "Link to Azure Machine Learning Portal: https://ml.azure.com/runs/0def4b27-451d-4e2e-8940-1c40bf6dfc01?wsid=/subscriptions/b7bf924e-67c3-4e5b-a5a7-3a2988311e4c/resourcegroups/dp-100/workspaces/lkftest&tid=e54f6a3d-b8e3-4e00-bbbf-c7a65d1e76b0\n",
            "StepRun( Train and Register Model ) Status: Running\n",
            "\n",
            "Streaming azureml-logs/55_azureml-execution-tvmps_b8452806c64ead682d779f49c85ab1dde905589d561602cce286aa7980a922bd_d.txt\n",
            "========================================================================================================================\n",
            "2021-05-18T15:01:54Z Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01/mounts/workspaceblobstore\n",
            "2021-05-18T15:01:55Z Starting output-watcher...\n",
            "2021-05-18T15:01:55Z IsDedicatedCompute == True, won't poll for Low Pri Preemption\n",
            "2021-05-18T15:01:55Z Executing 'Copy ACR Details file' on 10.0.0.5\n",
            "2021-05-18T15:01:55Z Copy ACR Details file succeeded on 10.0.0.5. Output: \n",
            ">>>   \n",
            ">>>   \n",
            "Login Succeeded\n",
            "Using default tag: latest\n",
            "latest: Pulling from azureml/azureml_443e6f417ae4fd3295e21acd32219350\n",
            "Digest: sha256:9b0f5eccbd45f901e8ed5166f10b79cc561983676cbd378df967ed32d93de5c7\n",
            "Status: Image is up to date for 3d8c8017d49a4265abf7f2d185cffa18.azurecr.io/azureml/azureml_443e6f417ae4fd3295e21acd32219350:latest\n",
            "3d8c8017d49a4265abf7f2d185cffa18.azurecr.io/azureml/azureml_443e6f417ae4fd3295e21acd32219350:latest\n",
            "2021-05-18T15:01:56Z Check if container 0def4b27-451d-4e2e-8940-1c40bf6dfc01 already exist exited with 0, \n",
            "\n",
            "0cc5d7ece9fecd45dea2d986f27fcc128000c23a5366362ecb67cb2e5a85fab2\n",
            "2021-05-18T15:01:56Z Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
            "2021-05-18T15:01:56Z containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-8f431454e644499a4a4dbf2da0be7b38-5026fb4fff8768a4-01 -sshRequired=false] \n",
            "2021/05/18 15:01:56 Starting App Insight Logger for task:  containerSetup\n",
            "2021/05/18 15:01:56 Version: 3.0.01597.0004 Branch: 2021-05-17-bing-hotfix Commit: 974f3e4\n",
            "2021/05/18 15:01:56 Entered ContainerSetupTask - Preparing infiniband\n",
            "2021/05/18 15:01:56 Starting infiniband setup\n",
            "2021/05/18 15:01:56 Python Version found is Python 3.6.2 :: Anaconda, Inc.\n",
            "\n",
            "2021/05/18 15:01:56 Returning Python Version as 3.6\n",
            "2021/05/18 15:01:56 VMSize: standard_ds3_v2, Host: ubuntu-18, Container: ubuntu-16.04\n",
            "2021/05/18 15:01:56 VMSize: standard_ds3_v2, Host: ubuntu-18, Container: ubuntu-16.04\n",
            "2021-05-18T15:01:56Z VMSize: standard_ds3_v2, Host: ubuntu-18, Container: ubuntu-16.04\n",
            "2021-05-18T15:01:57Z Not setting up Infiniband in Container\n",
            "2021/05/18 15:01:57 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
            "2021/05/18 15:01:57 Not setting up Infiniband in Container\n",
            "2021/05/18 15:01:57 Not setting up Infiniband in Container\n",
            "2021/05/18 15:01:57 Python Version found is Python 3.6.2 :: Anaconda, Inc.\n",
            "\n",
            "2021/05/18 15:01:57 Returning Python Version as 3.6\n",
            "2021/05/18 15:01:57 sshd inside container not required for job, skipping setup.\n",
            "2021/05/18 15:01:57 All App Insights Logs was send successfully\n",
            "2021/05/18 15:01:57 App Insight Client has already been closed\n",
            "2021/05/18 15:01:57 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
            "Stopped: false\n",
            "OriginalData: 1\n",
            "FilteredData: 0.\n",
            "2021-05-18T15:01:57Z Starting docker container succeeded.\n",
            "2021-05-18T15:02:01Z Job environment preparation succeeded on 10.0.0.5. Output: \n",
            ">>>   2021/05/18 15:01:54 Starting App Insight Logger for task:  prepareJobEnvironment\n",
            ">>>   2021/05/18 15:01:54 Version: 3.0.01597.0004 Branch: 2021-05-17-bing-hotfix Commit: 974f3e4\n",
            ">>>   2021/05/18 15:01:54 runtime.GOOS linux\n",
            ">>>   2021/05/18 15:01:54 Checking if '/tmp' exists\n",
            ">>>   2021/05/18 15:01:54 Reading dyanamic configs\n",
            ">>>   2021/05/18 15:01:54 Container sas url: https://baiscriptseastusprod.blob.core.windows.net/aihosttools?sv=2018-03-28&sr=c&si=aihosttoolspolicy&sig=gCpFfTbL8hPl%2BzV43hBdfOZC4SuKqZoJraIo10S4%2FYw%3D\n",
            ">>>   2021/05/18 15:01:54 Failed to read from file /mnt/batch/tasks/startup/wd/az_resource/xdsenv.variable/azsecpack.variables, open /mnt/batch/tasks/startup/wd/az_resource/xdsenv.variable/azsecpack.variables: no such file or directory\n",
            ">>>   2021/05/18 15:01:54 [in autoUpgradeFromJobNodeSetup] Is Azsecpack installer on host: false. Is Azsecpack enabled: false,\n",
            ">>>   2021/05/18 15:01:54 Starting Azsecpack installation on machine: lkftest#e54f6a3d-b8e3-4e00-bbbf-c7a65d1e76b0#b7bf924e-67c3-4e5b-a5a7-3a2988311e4c#dp-100#lkftest#lkftest\n",
            ">>>   2021/05/18 15:01:54 Is Azsecpack enabled: false, GetDisableVsatlsscan: true\n",
            ">>>   2021/05/18 15:01:54 Turning off azsecpack, if it is already running\n",
            ">>>   2021/05/18 15:01:54 [doTurnOffAzsecpack] output:Unit mdsd.service could not be found.\n",
            ">>>   ,err:exit status 1.\n",
            ">>>   2021/05/18 15:01:54 OS patching disabled by dynamic configs. Skipping.\n",
            ">>>   2021/05/18 15:01:54 Job: AZ_BATCHAI_JOB_NAME does not turn on the DetonationChamber\n",
            ">>>   2021/05/18 15:01:54 Start to getting gpu count by running nvidia-smi command\n",
            ">>>   2021/05/18 15:01:54 GPU count found on the node: 0\n",
            ">>>   2021/05/18 15:01:54 AMLComputeXDSEndpoint:  https://eastus-prodk8ds.batchai.core.windows.net\n",
            ">>>   2021/05/18 15:01:54 AMLComputeXDSApiVersion:  2018-02-01\n",
            ">>>   2021/05/18 15:01:54 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01/config\n",
            ">>>   2021/05/18 15:01:54 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01/wd\n",
            ">>>   2021/05/18 15:01:54 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01/shared\n",
            ">>>   2021/05/18 15:01:54 From the policy service, the filtering patterns is: , data store is \n",
            ">>>   2021/05/18 15:01:54 Mounting job level file systems\n",
            ">>>   2021/05/18 15:01:54 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01/mounts\n",
            ">>>   2021/05/18 15:01:54 Attempting to read datastore credentials file: /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01/config/.amlcompute.datastorecredentials\n",
            ">>>   2021/05/18 15:01:54 Datastore credentials file not found, skipping.\n",
            ">>>   2021/05/18 15:01:54 Attempting to read runtime sas tokens file: /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01/config/.master.runtimesastokens\n",
            ">>>   2021/05/18 15:01:54 Runtime sas tokens file not found, skipping.\n",
            ">>>   2021/05/18 15:01:54 No NFS configured\n",
            ">>>   2021/05/18 15:01:54 No Azure File Shares configured\n",
            ">>>   2021/05/18 15:01:54 Mounting blob file systems\n",
            ">>>   2021/05/18 15:01:54 Blobfuse runtime version 1.3.6\n",
            ">>>   2021/05/18 15:01:54 Mounting azureml-blobstore-3d8c8017-d49a-4265-abf7-f2d185cffa18 container from lkftest7730197733 account at /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01/mounts/workspaceblobstore\n",
            ">>>   2021/05/18 15:01:54 Error opening env file:  open /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01/config/.batchai.IdentityResponder.envlist: no such file or directory\n",
            ">>>   2021/05/18 15:01:54 Using Compute Identity to authenticate Blobfuse: false.\n",
            ">>>   2021/05/18 15:01:54 Using Compute Identity to authenticate Blobfuse: false.\n",
            ">>>   2021/05/18 15:01:54 Blobfuse cache size set to 24569 MB.\n",
            ">>>   2021/05/18 15:01:54 Running following command: /bin/bash -c sudo blobfuse /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01/mounts/workspaceblobstore --tmp-path=/mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01/caches/workspaceblobstore --file-cache-timeout-in-seconds=1000000 --cache-size-mb=24569 -o nonempty -o allow_other --config-file=/mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01/configs/workspaceblobstore.cfg --log-level=LOG_WARNING\n",
            ">>>   2021/05/18 15:01:54 Successfully mounted a/an Blobfuse File System at /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01/mounts/workspaceblobstore\n",
            ">>>   2021/05/18 15:01:55 Waiting for blobfs to be mounted at /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01/mounts/workspaceblobstore\n",
            ">>>   2021/05/18 15:01:55 Successfully mounted azureml-blobstore-3d8c8017-d49a-4265-abf7-f2d185cffa18 container from lkftest7730197733 account at /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01/mounts/workspaceblobstore\n",
            ">>>   2021/05/18 15:01:55 Created run_id directory: /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01/mounts/workspaceblobstore/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01\n",
            ">>>   2021/05/18 15:01:55 No unmanaged file systems configured\n",
            ">>>   2021/05/18 15:01:55 Start to getting gpu count by running nvidia-smi command\n",
            ">>>   2021/05/18 15:01:55 From the policy service, the filtering patterns is: , data store is \n",
            ">>>   2021/05/18 15:01:55 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01/mounts/workspaceblobstore/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01/azureml_compute_logs\n",
            ">>>   2021/05/18 15:01:55 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01/mounts/workspaceblobstore/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01/logs\n",
            ">>>   2021/05/18 15:01:55 Creating directory /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01/mounts/workspaceblobstore/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01/outputs\n",
            ">>>   2021/05/18 15:01:55 Starting output-watcher...\n",
            ">>>   2021/05/18 15:01:55 Single file input dataset is enabled.\n",
            ">>>   2021/05/18 15:01:55 Start to pulling docker image: 3d8c8017d49a4265abf7f2d185cffa18.azurecr.io/azureml/azureml_443e6f417ae4fd3295e21acd32219350\n",
            ">>>   2021/05/18 15:01:55 Start pull docker image: 3d8c8017d49a4265abf7f2d185cffa18.azurecr.io\n",
            ">>>   2021/05/18 15:01:55 Getting credentials for image 3d8c8017d49a4265abf7f2d185cffa18.azurecr.io/azureml/azureml_443e6f417ae4fd3295e21acd32219350 with url 3d8c8017d49a4265abf7f2d185cffa18.azurecr.io\n",
            ">>>   2021/05/18 15:01:55 Container registry is ACR.\n",
            ">>>   2021/05/18 15:01:55 Skip getting ACR Credentials from Identity and will be getting it from EMS\n",
            ">>>   2021/05/18 15:01:55 Getting ACR Credentials from EMS for environment diabetes-pipeline-env:1\n",
            ">>>   2021/05/18 15:01:55 Requesting XDS for registry details.\n",
            ">>>   2021/05/18 15:01:55 Attempt 1 of http call to https://eastus-prodk8ds.batchai.core.windows.net/hosttoolapi/subscriptions/b7bf924e-67c3-4e5b-a5a7-3a2988311e4c/resourceGroups/dp-100/workspaces/lkftest/clusters/lkftest/nodes/tvmps_b8452806c64ead682d779f49c85ab1dde905589d561602cce286aa7980a922bd_d?api-version=2018-02-01\n",
            ">>>   2021/05/18 15:01:55 Got container registry details from credentials service for registry address: 3d8c8017d49a4265abf7f2d185cffa18.azurecr.io.\n",
            ">>>   2021/05/18 15:01:55 Writing ACR Details to file...\n",
            ">>>   2021/05/18 15:01:55 Copying ACR Details file to worker nodes...\n",
            ">>>   2021/05/18 15:01:55 Executing 'Copy ACR Details file' on 10.0.0.5\n",
            ">>>   2021/05/18 15:01:55 Begin executing 'Copy ACR Details file' task on Node\n",
            ">>>   2021/05/18 15:01:55 'Copy ACR Details file' task Node result: succeeded\n",
            ">>>   2021/05/18 15:01:55 Copy ACR Details file succeeded on 10.0.0.5. Output: \n",
            ">>>   >>>   \n",
            ">>>   >>>   \n",
            ">>>   2021/05/18 15:01:55 Successfully retrieved ACR Credentials from EMS.\n",
            ">>>   2021/05/18 15:01:55 EMS returned 3d8c8017d49a4265abf7f2d185cffa18.azurecr.io for environment diabetes-pipeline-env\n",
            ">>>   2021/05/18 15:01:55 Save docker credentials for image 3d8c8017d49a4265abf7f2d185cffa18.azurecr.io/azureml/azureml_443e6f417ae4fd3295e21acd32219350 in /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01/wd/docker_login_8724C4F6F2A4365A\n",
            ">>>   2021/05/18 15:01:55 start login to the docker registry\n",
            ">>>   2021/05/18 15:01:55 Successfully logged into the docker registry.\n",
            ">>>   2021/05/18 15:01:55 Start run pull docker image command\n",
            ">>>   2021/05/18 15:01:56 Pull docker image succeeded.\n",
            ">>>   2021/05/18 15:01:56 Removed docker config dir /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01/wd/docker_login_8724C4F6F2A4365A\n",
            ">>>   2021/05/18 15:01:56 Pull docker image time: 694.733458ms\n",
            ">>>   \n",
            ">>>   2021/05/18 15:01:56 Docker Version that this nodes use are: 20.10.6+azure\n",
            ">>>   \n",
            ">>>   2021/05/18 15:01:56 Start to getting gpu count by running nvidia-smi command\n",
            ">>>   2021/05/18 15:01:56 Setting the memory limit for docker container to be 13647 MB\n",
            ">>>   2021/05/18 15:01:56 The env variable file size is 39639 bytes\n",
            ">>>   2021/05/18 15:01:56 Creating parent cgroup '0def4b27-451d-4e2e-8940-1c40bf6dfc01' for Containers used in Job\n",
            ">>>   2021/05/18 15:01:56 Add parent cgroup '0def4b27-451d-4e2e-8940-1c40bf6dfc01' to container '0def4b27-451d-4e2e-8940-1c40bf6dfc01'\n",
            ">>>   2021/05/18 15:01:56 /dev/infiniband/uverbs0 found (implying presence of InfiniBand)?: false\n",
            ">>>   2021/05/18 15:01:56 Original Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,0def4b27-451d-4e2e-8940-1c40bf6dfc01,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/workitems/58005e7e-7554-49c5-b0d8-6052379f4cae/job-1/0def4b27-451d-4e2e-8_a98c6052-da5f-4f33-bea4-63cf520ece36/certs:/mnt/batch/tasks/workitems/58005e7e-7554-49c5-b0d8-6052379f4cae/job-1/0def4b27-451d-4e2e-8_a98c6052-da5f-4f33-bea4-63cf520ece36/certs,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,-m,13647m,-v,/mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01/mounts/workspaceblobstore/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01/mounts/workspaceblobstore/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01/azureml_compute_logs,-v,/mnt/batch/tasks/workitems/58005e7e-7554-49c5-b0d8-6052379f4cae/job-1/0def4b27-451d-4e2e-8_a98c6052-da5f-4f33-bea4-63cf520ece36/wd:/mnt/batch/tasks/workitems/58005e7e-7554-49c5-b0d8-6052379f4cae/job-1/0def4b27-451d-4e2e-8_a98c6052-da5f-4f33-bea4-63cf520ece36/wd,-v,/mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01:/mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01,-v,/mnt/batch/tasks/shared/LS_root/shared/tracing/0def4b27-451d-4e2e-8940-1c40bf6dfc01/logs/azureml/tracing:/mnt/batch/tasks/shared/LS_root/shared/tracing/0def4b27-451d-4e2e-8940-1c40bf6dfc01/logs/azureml/tracing,-w,/mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01/config/.batchai.envlist,--cgroup-parent=/0def4b27-451d-4e2e-8940-1c40bf6dfc01/,--shm-size,2g\n",
            ">>>   2021/05/18 15:01:56 the binding /mnt/batch/tasks/shared/LS_root/shared/tracing/0def4b27-451d-4e2e-8940-1c40bf6dfc01/logs/azureml/tracing:/mnt/batch/tasks/shared/LS_root/shared/tracing/0def4b27-451d-4e2e-8940-1c40bf6dfc01/logs/azureml/tracing is discarded as we already have /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared \n",
            ">>>   2021/05/18 15:01:56 the binding /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01/mounts/workspaceblobstore/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01/azureml_compute_logs:/mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01/mounts/workspaceblobstore/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01/azureml_compute_logs is discarded as we already have /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01:/mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01 \n",
            ">>>   2021/05/18 15:01:56 Updated Arguments: run,--ulimit,memlock=9223372036854775807,--ulimit,nofile=262144:262144,--cap-add,sys_ptrace,--name,0def4b27-451d-4e2e-8940-1c40bf6dfc01,-m,13647m,-w,/mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01/wd,--expose,23,--env-file,/mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01/config/.batchai.envlist,--cgroup-parent=/0def4b27-451d-4e2e-8940-1c40bf6dfc01/,--shm-size,2g,-v,/mnt/batch/tasks/startup:/mnt/batch/tasks/startup,-v,/mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared,-v,/mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared,-v,/mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs,-v,/mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01:/mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01,-v,/mnt/batch/tasks/workitems/58005e7e-7554-49c5-b0d8-6052379f4cae/job-1/0def4b27-451d-4e2e-8_a98c6052-da5f-4f33-bea4-63cf520ece36/wd:/mnt/batch/tasks/workitems/58005e7e-7554-49c5-b0d8-6052379f4cae/job-1/0def4b27-451d-4e2e-8_a98c6052-da5f-4f33-bea4-63cf520ece36/wd,-v,/mnt/batch/tasks/workitems/58005e7e-7554-49c5-b0d8-6052379f4cae/job-1/0def4b27-451d-4e2e-8_a98c6052-da5f-4f33-bea4-63cf520ece36/certs:/mnt/batch/tasks/workitems/58005e7e-7554-49c5-b0d8-6052379f4cae/job-1/0def4b27-451d-4e2e-8_a98c6052-da5f-4f33-bea4-63cf520ece36/certs\n",
            ">>>   2021/05/18 15:01:56 Running Docker command: docker run --ulimit memlock=9223372036854775807 --ulimit nofile=262144:262144 --cap-add sys_ptrace --name 0def4b27-451d-4e2e-8940-1c40bf6dfc01 -m 13647m -w /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01/wd --expose 23 --env-file /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01/config/.batchai.envlist --cgroup-parent=/0def4b27-451d-4e2e-8940-1c40bf6dfc01/ --shm-size 2g -v /mnt/batch/tasks/startup:/mnt/batch/tasks/startup -v /mnt/batch/tasks/shared/LS_root/mounts:/mnt/batch/tasks/shared/LS_root/mounts:rshared -v /mnt/batch/tasks/shared/LS_root/shared:/mnt/batch/tasks/shared/LS_root/shared -v /mnt/batch/tasks/shared/LS_root/configs:/mnt/batch/tasks/shared/LS_root/configs -v /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01:/mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01 -v /mnt/batch/tasks/workitems/58005e7e-7554-49c5-b0d8-6052379f4cae/job-1/0def4b27-451d-4e2e-8_a98c6052-da5f-4f33-bea4-63cf520ece36/wd:/mnt/batch/tasks/workitems/58005e7e-7554-49c5-b0d8-6052379f4cae/job-1/0def4b27-451d-4e2e-8_a98c6052-da5f-4f33-bea4-63cf520ece36/wd -v /mnt/batch/tasks/workitems/58005e7e-7554-49c5-b0d8-6052379f4cae/job-1/0def4b27-451d-4e2e-8_a98c6052-da5f-4f33-bea4-63cf520ece36/certs:/mnt/batch/tasks/workitems/58005e7e-7554-49c5-b0d8-6052379f4cae/job-1/0def4b27-451d-4e2e-8_a98c6052-da5f-4f33-bea4-63cf520ece36/certs -d -it --privileged --net=host 3d8c8017d49a4265abf7f2d185cffa18.azurecr.io/azureml/azureml_443e6f417ae4fd3295e21acd32219350\n",
            ">>>   2021/05/18 15:01:56 Check if container 0def4b27-451d-4e2e-8940-1c40bf6dfc01 already exist exited with 0, \n",
            ">>>   \n",
            ">>>   2021/05/18 15:01:56 Check if container 0def4b27-451d-4e2e-8940-1c40bf6dfc01 already exist exited with 0, \n",
            ">>>   \n",
            ">>>   2021/05/18 15:01:56 Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
            ">>>   2021/05/18 15:01:56 Parameters for containerSetup task: useDetonationChamer set to false and sshRequired set to false \n",
            ">>>   2021/05/18 15:01:56 containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-8f431454e644499a4a4dbf2da0be7b38-5026fb4fff8768a4-01 -sshRequired=false] \n",
            ">>>   2021/05/18 15:01:56 containerSetup task cmd: [/mnt/batch/tasks/startup/wd/hosttools -task=containerSetup -traceContext=00-8f431454e644499a4a4dbf2da0be7b38-5026fb4fff8768a4-01 -sshRequired=false] \n",
            ">>>   2021/05/18 15:01:57 Container ssh is not required for job type.\n",
            ">>>   2021/05/18 15:01:57 Starting docker container succeeded.\n",
            ">>>   2021/05/18 15:01:57 Starting docker container succeeded.\n",
            ">>>   2021/05/18 15:01:57 Disk space after starting docker container: 26022MB\n",
            ">>>   2021/05/18 15:01:57 Begin execution of runSpecialJobTask\n",
            ">>>   2021/05/18 15:01:57 runSpecialJobTask: os.GetEnv constants.StdouterrDir: /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01/mounts/workspaceblobstore/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01/azureml_compute_logs\n",
            ">>>   2021/05/18 15:01:57 runSpecialJobTask: Raw cmd for preparation is passed is: /azureml-envs/azureml_28b0d742a4cb5c02a5befb218632cd1a/bin/python /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01/mounts/workspaceblobstore/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"8510d385-f92b-4469-b7e4-5f7ffc3c9021\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
            ">>>   2021/05/18 15:01:57 runSpecialJobTask: stdout path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01/mounts/workspaceblobstore/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01/azureml_compute_logs/65_job_prep-tvmps_b8452806c64ead682d779f49c85ab1dde905589d561602cce286aa7980a922bd_d.txt\n",
            ">>>   2021/05/18 15:01:57 runSpecialJobTask: stderr path for preparation is passed is: /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01/mounts/workspaceblobstore/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01/azureml_compute_logs/65_job_prep-tvmps_b8452806c64ead682d779f49c85ab1dde905589d561602cce286aa7980a922bd_d.txt\n",
            ">>>   2021/05/18 15:01:57 native cmd: export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/58005e7e-7554-49c5-b0d8-6052379f4cae/job-1/0def4b27-451d-4e2e-8_a98c6052-da5f-4f33-bea4-63cf520ece36/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01/mounts/workspaceblobstore/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01;/azureml-envs/azureml_28b0d742a4cb5c02a5befb218632cd1a/bin/python /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01/mounts/workspaceblobstore/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"8510d385-f92b-4469-b7e4-5f7ffc3c9021\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
            ">>>   2021/05/18 15:01:57 runSpecialJobTask: commons.GetOsPlatform(): ubuntu\n",
            ">>>   2021/05/18 15:01:57 runSpecialJobTask: Running cmd: /usr/bin/docker exec -e AZUREML_SDK_TRACEPARENT=00-8f431454e644499a4a4dbf2da0be7b38-a2371d506e7486c6-01 -t 0def4b27-451d-4e2e-8940-1c40bf6dfc01 bash -c source /etc/bash.bashrc; PATH=$PATH:$AZ_BATCH_NODE_STARTUP_DIR/wd/;export AZUREML_JOB_TASK_ERROR_PATH='/mnt/batch/tasks/workitems/58005e7e-7554-49c5-b0d8-6052379f4cae/job-1/0def4b27-451d-4e2e-8_a98c6052-da5f-4f33-bea4-63cf520ece36/wd/runSpecialJobTask_error.json';cd /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01/mounts/workspaceblobstore/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01;/azureml-envs/azureml_28b0d742a4cb5c02a5befb218632cd1a/bin/python /mnt/batch/tasks/shared/LS_root/jobs/lkftest/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01/mounts/workspaceblobstore/azureml/0def4b27-451d-4e2e-8940-1c40bf6dfc01-setup/job_prep.py -i DataStoreCopy:context_managers.DataStores --snapshots '[{\"Id\":\"8510d385-f92b-4469-b7e4-5f7ffc3c9021\",\"PathStack\":[\".\"],\"SnapshotEntityId\":null}]'\n",
            ">>>   2021/05/18 15:01:59 Attempt 1 of http call to https://eastus.api.azureml.ms/history/v1.0/private/subscriptions/b7bf924e-67c3-4e5b-a5a7-3a2988311e4c/resourceGroups/dp-100/providers/Microsoft.MachineLearningServices/workspaces/lkftest/runs/0def4b27-451d-4e2e-8940-1c40bf6dfc01/spans\n",
            ">>>   2021/05/18 15:02:01 runSpecialJobTask: job preparation exited with code 0 and err <nil>\n",
            ">>>   \n",
            ">>>   2021/05/18 15:02:01 runSpecialJobTask: preparation: [2021-05-18T15:01:58.155923] Entering job preparation.\n",
            ">>>   2021/05/18 15:02:01 runSpecialJobTask: preparation: [2021-05-18T15:01:59.528224] Starting job preparation.\n",
            ">>>   2021/05/18 15:02:01 runSpecialJobTask: preparation: [2021-05-18T15:01:59.528263] Extracting the control code.\n",
            ">>>   2021/05/18 15:02:01 runSpecialJobTask: preparation: [2021-05-18T15:01:59.546283] fetching and extracting the control code on master node.\n",
            ">>>   2021/05/18 15:02:01 runSpecialJobTask: preparation: [2021-05-18T15:01:59.546313] Starting extract_project.\n",
            ">>>   2021/05/18 15:02:01 runSpecialJobTask: preparation: [2021-05-18T15:01:59.546372] Starting to extract zip file.\n",
            ">>>   2021/05/18 15:02:01 runSpecialJobTask: preparation: [2021-05-18T15:02:00.111305] Finished extracting zip file.\n",
            ">>>   2021/05/18 15:02:01 runSpecialJobTask: preparation: [2021-05-18T15:02:00.353821] Using urllib.request Python 3.0 or later\n",
            ">>>   2021/05/18 15:02:01 runSpecialJobTask: preparation: [2021-05-18T15:02:00.353895] Start fetching snapshots.\n",
            ">>>   2021/05/18 15:02:01 runSpecialJobTask: preparation: [2021-05-18T15:02:00.353942] Start fetching snapshot.\n",
            ">>>   2021/05/18 15:02:01 runSpecialJobTask: preparation: [2021-05-18T15:02:00.353959] Retrieving project from snapshot: 8510d385-f92b-4469-b7e4-5f7ffc3c9021\n",
            ">>>   2021/05/18 15:02:01 runSpecialJobTask: preparation: Starting the daemon thread to refresh tokens in background for process with pid = 44\n",
            ">>>   2021/05/18 15:02:01 runSpecialJobTask: preparation: [2021-05-18T15:02:00.546866] Finished fetching snapshot.\n",
            ">>>   2021/05/18 15:02:01 runSpecialJobTask: preparation: [2021-05-18T15:02:00.546919] Finished fetching snapshots.\n",
            ">>>   2021/05/18 15:02:01 runSpecialJobTask: preparation: [2021-05-18T15:02:00.546948] Finished extract_project.\n",
            ">>>   2021/05/18 15:02:01 runSpecialJobTask: preparation: [2021-05-18T15:02:00.561378] Finished fetching and extracting the control code.\n",
            ">>>   2021/05/18 15:02:01 runSpecialJobTask: preparation: [2021-05-18T15:02:00.565244] downloadDataStore - Download from datastores if requested.\n",
            ">>>   2021/05/18 15:02:01 runSpecialJobTask: preparation: [2021-05-18T15:02:00.566257] Start run_history_prep.\n",
            ">>>   2021/05/18 15:02:01 runSpecialJobTask: preparation: [2021-05-18T15:02:00.623897] Entering context manager injector.\n",
            ">>>   2021/05/18 15:02:01 runSpecialJobTask: preparation: Acquired lockfile /tmp/0def4b27-451d-4e2e-8940-1c40bf6dfc01-datastore.lock to downloading input data references\n",
            ">>>   2021/05/18 15:02:01 runSpecialJobTask: preparation: [2021-05-18T15:02:01.240618] downloadDataStore completed\n",
            ">>>   2021/05/18 15:02:01 runSpecialJobTask: preparation: [2021-05-18T15:02:01.244361] Job preparation is complete.\n",
            ">>>   2021/05/18 15:02:01 Execution of runSpecialJobTask completed\n",
            ">>>   2021/05/18 15:02:01 Not exporting to RunHistory as the exporter is either stopped or there is no data.\n",
            ">>>   Stopped: false\n",
            ">>>   OriginalData: 3\n",
            ">>>   FilteredData: 0.\n",
            ">>>   2021/05/18 15:02:01 Process Exiting with Code:  0\n",
            ">>>   2021/05/18 15:02:01 All App Insights Logs was send successfully\n",
            ">>>   \n",
            "2021-05-18T15:02:01Z 127.0.0.1 slots=4 max-slots=4\n",
            "2021-05-18T15:02:02Z launching Custom job\n",
            "\n",
            "Streaming azureml-logs/75_job_post-tvmps_b8452806c64ead682d779f49c85ab1dde905589d561602cce286aa7980a922bd_d.txt\n",
            "===============================================================================================================\n",
            "[2021-05-18T15:02:17.701436] Entering job release\n",
            "[2021-05-18T15:02:18.755035] Starting job release\n",
            "[2021-05-18T15:02:18.760236] Logging experiment finalizing status in history service.\n",
            "Starting the daemon thread to refresh tokens in background for process with pid = 148\n",
            "[2021-05-18T15:02:18.760532] job release stage : upload_datastore starting...\n",
            "[2021-05-18T15:02:18.760914] job release stage : start importing azureml.history._tracking in run_history_release.\n",
            "[2021-05-18T15:02:18.761291] job release stage : copy_batchai_cached_logs starting...\n",
            "[2021-05-18T15:02:18.763345] job release stage : execute_job_release starting...\n",
            "[2021-05-18T15:02:18.763461] job release stage : copy_batchai_cached_logs completed...\n",
            "[2021-05-18T15:02:18.770332] Entering context manager injector.\n",
            "[2021-05-18T15:02:18.793341] job release stage : upload_datastore completed...\n",
            "[2021-05-18T15:02:18.913423] job release stage : execute_job_release completed...\n",
            "[2021-05-18T15:02:18.923029] job release stage : send_run_telemetry starting...\n",
            "[2021-05-18T15:02:19.235459] get vm size and vm region successfully.\n",
            "[2021-05-18T15:02:19.540250] get compute meta data successfully.\n",
            "[2021-05-18T15:02:19.685264] post artifact meta request successfully.\n",
            "[2021-05-18T15:02:19.712534] upload compute record artifact successfully.\n",
            "[2021-05-18T15:02:19.712606] job release stage : send_run_telemetry completed...\n",
            "[2021-05-18T15:02:19.712890] Job release is complete\n",
            "\n",
            "StepRun(Train and Register Model) Execution Summary\n",
            "====================================================\n",
            "StepRun( Train and Register Model ) Status: Finished\n",
            "{'runId': '0def4b27-451d-4e2e-8940-1c40bf6dfc01', 'target': 'lkftest', 'status': 'Completed', 'startTimeUtc': '2021-05-18T15:01:54.950093Z', 'endTimeUtc': '2021-05-18T15:02:29.548775Z', 'properties': {'ContentSnapshotId': '8510d385-f92b-4469-b7e4-5f7ffc3c9021', 'StepType': 'PythonScriptStep', 'azureml.moduleid': '0f96d972-d4ff-454d-bb1b-a5d35331c7d3', 'azureml.runsource': 'azureml.StepRun', 'azureml.nodeid': 'b0be7842', 'azureml.pipelinerunid': '047ec2f9-08ed-48b0-b903-f4695490d92f', '_azureml.ComputeTargetType': 'amlcompute', 'ProcessInfoFile': 'azureml-logs/process_info.json', 'ProcessStatusFile': 'azureml-logs/process_status.json'}, 'inputDatasets': [], 'outputDatasets': [], 'runDefinition': {'script': 'train_diabetes.py', 'command': '', 'useAbsolutePath': False, 'arguments': ['--training-folder', '$AZUREML_DATAREFERENCE_prepped_data_folder'], 'sourceDirectoryDataStore': None, 'framework': 'Python', 'communicator': 'None', 'target': 'lkftest', 'dataReferences': {'prepped_data_folder': {'dataStoreName': 'workspaceblobstore', 'mode': 'Mount', 'pathOnDataStore': 'azureml/8b7674e5-b587-4fac-aeff-7b0d59fc577e/prepped_data_folder', 'pathOnCompute': None, 'overwrite': False}}, 'data': {}, 'outputData': {}, 'jobName': None, 'maxRunDurationSeconds': None, 'nodeCount': 1, 'priority': None, 'credentialPassthrough': False, 'identity': None, 'environment': {'name': 'diabetes-pipeline-env', 'version': '1', 'python': {'interpreterPath': 'python', 'userManagedDependencies': False, 'condaDependencies': {'channels': ['anaconda', 'conda-forge'], 'dependencies': ['python=3.6.2', {'pip': ['azureml-defaults~=1.27.0', 'azureml-dataprep[pandas]', 'pyarrow']}, 'scikit-learn', 'ipykernel', 'matplotlib', 'pandas', 'pip'], 'name': 'azureml_28b0d742a4cb5c02a5befb218632cd1a'}, 'baseCondaEnvironment': None}, 'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'}, 'docker': {'baseImage': 'mcr.microsoft.com/azureml/intelmpi2018.3-ubuntu16.04:20210301.v1', 'platform': {'os': 'Linux', 'architecture': 'amd64'}, 'baseDockerfile': None, 'dockerContext': None, 'baseImageRegistry': {'address': None, 'username': None, 'password': None}, 'enabled': False, 'arguments': []}, 'spark': {'repositories': [], 'packages': [], 'precachePackages': True}, 'inferencingStackVersion': None}, 'history': {'outputCollection': True, 'directoriesToWatch': ['logs'], 'enableMLflowTracking': True, 'snapshotProject': True}, 'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment', 'spark.yarn.maxAppAttempts': '1'}}, 'parallelTask': {'maxRetriesPerWorker': 0, 'workerCountPerNode': 1, 'terminalExitCodes': None, 'configuration': {}}, 'amlCompute': {'name': None, 'vmSize': None, 'retainCluster': False, 'clusterMaxNodeCount': 1}, 'aiSuperComputer': {'instanceType': None, 'imageVersion': None, 'location': None, 'aiSuperComputerStorageData': None, 'interactive': False, 'scalePolicy': None, 'virtualClusterArmId': None, 'tensorboardLogDirectory': None, 'sshPublicKey': None}, 'tensorflow': {'workerCount': 1, 'parameterServerCount': 1}, 'mpi': {'processCountPerNode': 1}, 'pyTorch': {'communicationBackend': 'nccl', 'processCount': None}, 'hdi': {'yarnDeployMode': 'Cluster'}, 'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5}, 'exposedPorts': None, 'docker': {'useDocker': False, 'sharedVolumes': True, 'shmSize': '2g', 'arguments': []}, 'cmk8sCompute': {'configuration': {}}, 'commandReturnCodeConfig': {'returnCode': 'Zero', 'successfulReturnCodes': []}, 'environmentVariables': {}, 'applicationEndpoints': {}}, 'logFiles': {'azureml-logs/55_azureml-execution-tvmps_b8452806c64ead682d779f49c85ab1dde905589d561602cce286aa7980a922bd_d.txt': 'https://lkftest7730197733.blob.core.windows.net/azureml/ExperimentRun/dcid.0def4b27-451d-4e2e-8940-1c40bf6dfc01/azureml-logs/55_azureml-execution-tvmps_b8452806c64ead682d779f49c85ab1dde905589d561602cce286aa7980a922bd_d.txt?sv=2019-02-02&sr=b&sig=QyGX4c%2BqkNc3mRgaLMzeUoVKRiY6uD0ezXlg6WD28Qk%3D&st=2021-05-18T14%3A52%3A21Z&se=2021-05-18T23%3A02%3A21Z&sp=r', 'azureml-logs/65_job_prep-tvmps_b8452806c64ead682d779f49c85ab1dde905589d561602cce286aa7980a922bd_d.txt': 'https://lkftest7730197733.blob.core.windows.net/azureml/ExperimentRun/dcid.0def4b27-451d-4e2e-8940-1c40bf6dfc01/azureml-logs/65_job_prep-tvmps_b8452806c64ead682d779f49c85ab1dde905589d561602cce286aa7980a922bd_d.txt?sv=2019-02-02&sr=b&sig=NdhjWp7oCRNx8tm6WM37J%2FdLMD4yNmVM4KCkZGuDo8g%3D&st=2021-05-18T14%3A52%3A21Z&se=2021-05-18T23%3A02%3A21Z&sp=r', 'azureml-logs/70_driver_log.txt': 'https://lkftest7730197733.blob.core.windows.net/azureml/ExperimentRun/dcid.0def4b27-451d-4e2e-8940-1c40bf6dfc01/azureml-logs/70_driver_log.txt?sv=2019-02-02&sr=b&sig=2xSV8h31%2B6%2FpFT1ASlcCt1NELid7SEpjn82TRXVQ1hM%3D&st=2021-05-18T14%3A52%3A21Z&se=2021-05-18T23%3A02%3A21Z&sp=r', 'azureml-logs/75_job_post-tvmps_b8452806c64ead682d779f49c85ab1dde905589d561602cce286aa7980a922bd_d.txt': 'https://lkftest7730197733.blob.core.windows.net/azureml/ExperimentRun/dcid.0def4b27-451d-4e2e-8940-1c40bf6dfc01/azureml-logs/75_job_post-tvmps_b8452806c64ead682d779f49c85ab1dde905589d561602cce286aa7980a922bd_d.txt?sv=2019-02-02&sr=b&sig=q7tBXjCrARvBOtBbohFu3hegsH5lFPPx2RuBO%2FYsDRY%3D&st=2021-05-18T14%3A52%3A21Z&se=2021-05-18T23%3A02%3A21Z&sp=r', 'azureml-logs/process_info.json': 'https://lkftest7730197733.blob.core.windows.net/azureml/ExperimentRun/dcid.0def4b27-451d-4e2e-8940-1c40bf6dfc01/azureml-logs/process_info.json?sv=2019-02-02&sr=b&sig=yqUZ2FlzOBgY100SecpjwOXP0nXWXnt9YuON%2BC%2FuA3I%3D&st=2021-05-18T14%3A52%3A21Z&se=2021-05-18T23%3A02%3A21Z&sp=r', 'azureml-logs/process_status.json': 'https://lkftest7730197733.blob.core.windows.net/azureml/ExperimentRun/dcid.0def4b27-451d-4e2e-8940-1c40bf6dfc01/azureml-logs/process_status.json?sv=2019-02-02&sr=b&sig=3ozGVI9VQw7ArpIEGp%2FjbJUoJMKYueVPInTlh62HVE0%3D&st=2021-05-18T14%3A52%3A21Z&se=2021-05-18T23%3A02%3A21Z&sp=r', 'logs/azureml/103_azureml.log': 'https://lkftest7730197733.blob.core.windows.net/azureml/ExperimentRun/dcid.0def4b27-451d-4e2e-8940-1c40bf6dfc01/logs/azureml/103_azureml.log?sv=2019-02-02&sr=b&sig=emBhcX9LBDePuqovA%2BtS8hS9SNyPqB6V6eB1MZmOA74%3D&st=2021-05-18T14%3A52%3A21Z&se=2021-05-18T23%3A02%3A21Z&sp=r', 'logs/azureml/executionlogs.txt': 'https://lkftest7730197733.blob.core.windows.net/azureml/ExperimentRun/dcid.0def4b27-451d-4e2e-8940-1c40bf6dfc01/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=nE4%2Fp48C4EYkp9Q%2BCxfZqVeLs%2FnNxaahh4lwXYIz4Cc%3D&st=2021-05-18T14%3A52%3A21Z&se=2021-05-18T23%3A02%3A21Z&sp=r', 'logs/azureml/job_prep_azureml.log': 'https://lkftest7730197733.blob.core.windows.net/azureml/ExperimentRun/dcid.0def4b27-451d-4e2e-8940-1c40bf6dfc01/logs/azureml/job_prep_azureml.log?sv=2019-02-02&sr=b&sig=9X0UH9D8XmawMpXwBut%2Fj4WfzVhIROcjYuoAq%2Fq66S4%3D&st=2021-05-18T14%3A52%3A21Z&se=2021-05-18T23%3A02%3A21Z&sp=r', 'logs/azureml/job_release_azureml.log': 'https://lkftest7730197733.blob.core.windows.net/azureml/ExperimentRun/dcid.0def4b27-451d-4e2e-8940-1c40bf6dfc01/logs/azureml/job_release_azureml.log?sv=2019-02-02&sr=b&sig=wmXdA10DgOl1Gn0DfqVdDYtWH1IAJyDWkwVHuO%2F1AVE%3D&st=2021-05-18T14%3A52%3A21Z&se=2021-05-18T23%3A02%3A21Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://lkftest7730197733.blob.core.windows.net/azureml/ExperimentRun/dcid.0def4b27-451d-4e2e-8940-1c40bf6dfc01/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=fZNpU%2B1TXDDKP1qVOI4nbkjt9YxwL%2B0Ho3s7jvWHhwU%3D&st=2021-05-18T14%3A52%3A21Z&se=2021-05-18T23%3A02%3A21Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://lkftest7730197733.blob.core.windows.net/azureml/ExperimentRun/dcid.0def4b27-451d-4e2e-8940-1c40bf6dfc01/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=sqfhFL050aYrpzNROXUiHog4LKW%2BXMJdpCR6XW4RlBQ%3D&st=2021-05-18T14%3A52%3A21Z&se=2021-05-18T23%3A02%3A21Z&sp=r'}, 'submittedBy': 'Landon Fowler'}\n",
            "\n",
            "\n",
            "\n",
            "PipelineRun Execution Summary\n",
            "==============================\n",
            "PipelineRun Status: Finished\n",
            "{'runId': '047ec2f9-08ed-48b0-b903-f4695490d92f', 'status': 'Completed', 'startTimeUtc': '2021-05-18T15:00:35.774477Z', 'endTimeUtc': '2021-05-18T15:02:30.681171Z', 'properties': {'azureml.runsource': 'azureml.PipelineRun', 'runSource': 'SDK', 'runType': 'SDK', 'azureml.parameters': '{}'}, 'inputDatasets': [], 'outputDatasets': [], 'logFiles': {'logs/azureml/executionlogs.txt': 'https://lkftest7730197733.blob.core.windows.net/azureml/ExperimentRun/dcid.047ec2f9-08ed-48b0-b903-f4695490d92f/logs/azureml/executionlogs.txt?sv=2019-02-02&sr=b&sig=pKWIb8vfc7Mm75DQ5hfuj8IoKwN3g%2B8KLBqaNif9Ot0%3D&st=2021-05-18T14%3A50%3A44Z&se=2021-05-18T23%3A00%3A44Z&sp=r', 'logs/azureml/stderrlogs.txt': 'https://lkftest7730197733.blob.core.windows.net/azureml/ExperimentRun/dcid.047ec2f9-08ed-48b0-b903-f4695490d92f/logs/azureml/stderrlogs.txt?sv=2019-02-02&sr=b&sig=fHdbcNWStrI6sbMPyvZ0EAB%2BMErbt2XIihrYmVE4HuE%3D&st=2021-05-18T14%3A50%3A44Z&se=2021-05-18T23%3A00%3A44Z&sp=r', 'logs/azureml/stdoutlogs.txt': 'https://lkftest7730197733.blob.core.windows.net/azureml/ExperimentRun/dcid.047ec2f9-08ed-48b0-b903-f4695490d92f/logs/azureml/stdoutlogs.txt?sv=2019-02-02&sr=b&sig=tRKe9A8R2wWySdcOUTSFV1yBU513Y32Nphm4B17Idqk%3D&st=2021-05-18T14%3A50%3A44Z&se=2021-05-18T23%3A00%3A44Z&sp=r'}, 'submittedBy': 'Landon Fowler'}\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": "'Finished'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 16,
      "metadata": {
        "scrolled": true,
        "gather": {
          "logged": 1621350152974
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}